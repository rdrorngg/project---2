{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "71VIkbQEMmjl"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 전처리 % 기본적인 EDA"
      ],
      "metadata": {
        "id": "7ZttWX6aMZYa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hK20l1h2bM0S",
        "outputId": "0bef3632-0e98-4d6c-e50a-49f874d85a8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "KZqqMzK0hvEa"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.read_csv('/content/drive/MyDrive/AI부트/Kickstarter_2023-01-05T03_20_04_136Z/Kickstarter.csv')\n",
        "df2 = pd.read_csv('/content/drive/MyDrive/AI부트/Kickstarter_2023-01-05T03_20_04_136Z/Kickstarter001.csv')\n",
        "df3 = pd.read_csv('/content/drive/MyDrive/AI부트/Kickstarter_2023-01-05T03_20_04_136Z/Kickstarter002.csv')"
      ],
      "metadata": {
        "id": "d1iwhZAXh43U"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "예시는 df1의 0번 기준\n",
        "\n",
        "backers_count : 프로젝트를 후원한 사람들의 수\n",
        "\n",
        "ex) 12\n",
        "\n",
        "blurb : 프로젝트에 대한 짧은 설명\n",
        "\n",
        "ex) A kung fu master gets canceled for defeating an Asian challenger because the victory is mistaken for a hate crime.\n",
        "\n",
        "category : 프로젝트의 카테고리\n",
        "\n",
        "ex) {\"id\":292,\"name\":\"Comedy\",\"analytics_name\":\"Comedy\",\"slug\":\"film & video/comedy\",\"position\":3,\"parent_id\":11,\"parent_name\":\"Film & Video\",\"color\":16734574,\"urls\":{\"web\":{\"discover\":\"http://www.kickstarter.com/discover/categories/film%20&%20video/comedy\"}}}\n",
        "\n",
        "\n",
        "converted_pledged_amount : 변환된 약정(펀딩) 금액, 해당 프로젝트에 대한 약정 금액\n",
        "\n",
        "ex) 619.0\n",
        "\n",
        "country : 국가\n",
        "\n",
        "ex) US\n",
        "\n",
        "country_displayable_name : 표시되는 국가명\n",
        "\n",
        "ex) the United States\n",
        "\n",
        "created_at : 프로젝트가 생성된 날짜\n",
        "\n",
        "ex) 1672609702\n",
        "\n",
        "creator : 제작자의 id 번호\n",
        "\n",
        "ex) {\"id\":584593596,\"name\":\"Michael J Kospiah\",\"slug\":\"michaeljkospiah\",\"is_registered\":null,\"is_email_verified\":null,\"chosen_currency\":null,\"is_superbacker\":null,\"avatar\":{\"thumb\":\"https://ksr-ugc.imgix.net/assets/039/567/599/c5aa2167684a9ee5bd155ace2ed61f34_original.jpg?ixlib=rb-4.0.2&w=40&h=40&fit=crop&v=1672623580&auto=format&frame=1&q=92&s=8971b6dc8e555d4283ff4cc9281eebb5\",\"small\":\"https://ksr-ugc.imgix.net/assets/039/567/599/c5aa2167684a9ee5bd155ace2ed61f34_original.jpg?ixlib=rb-4.0.2&w=80&h=80&fit=crop&v=1672623580&auto=format&frame=1&q=92&s=b77a8c514720dc8442beab8ea2f07a73\",\"medium\":\"https://ksr-ugc.imgix.net/assets/039/567/599/c5aa2167684a9ee5bd155ace2ed61f34_original.jpg?ixlib=rb-4.0.2&w=160&h=160&fit=crop&v=1672623580&auto=format&frame=1&q=92&s=f176e9b7f83fce8d726c90ea6fa2f160\"},\"urls\":{\"web\":{\"user\":\"https://www.kickstarter.com/profile/michaeljkospiah\"},\"api\":{\"user\":\"https://api.kickstarter.com/v1/users/584593596?signature=1672975215.9522df02a7f3860584bd472dfca7193dba9d83c7\"}}}\n",
        "\n",
        "\n",
        "currency : 통화\n",
        "\n",
        "ex) USD\n",
        "\n",
        "currency_symbol : 통화 기호\n",
        "\n",
        "ex) $\n",
        "\n",
        "currency_trailing_code : 통화에 trailing_code가 존재하는지의 여부\n",
        "\n",
        "ex) True\n",
        "\n",
        "current_currency : 현재 통화\n",
        "\n",
        "ex) USD\n",
        "\n",
        "deadline : 프로젝트의 기한\n",
        "\n",
        "ex) 1673852626\n",
        "\n",
        "disable_communication\n",
        "\n",
        "ex) False\n",
        "\n",
        "fx_rate : 외환거래 환율\n",
        "\n",
        "ex) 1.0\n",
        "\n",
        "goal : 목표치\n",
        "\n",
        "ex) 600\n",
        "\n",
        "id : 프로젝트 id\n",
        "\n",
        "ex) 1218249044\n",
        "\n",
        "is_starrable : Kickstarter가 해당 프로젝트가 성공했다고 판단했는지의 여부\n",
        "\n",
        "ex) True\n",
        "\n",
        "launched_at : 시작된 날짜\n",
        "\n",
        "ex) 1672643026\n",
        "\n",
        "location : 위치\n",
        "\n",
        "ex) {\"id\":2459115,\"name\":\"New York\",\"slug\":\"new-york-ny\",\"short_name\":\"New York, NY\",\"displayable_name\":\"New York, NY\",\"localized_name\":\"New York\",\"country\":\"US\",\"state\":\"NY\",\"type\":\"Town\",\"is_root\":false,\"expanded_country\":\"United States\",\"urls\":{\"web\":{\"discover\":\"https://www.kickstarter.com/discover/places/new-york-ny\",\"location\":\"https://www.kickstarter.com/locations/new-york-ny\"},\"api\":{\"nearby_projects\":\"https://api.kickstarter.com/v1/discover?signature=1672937661.51a36fee5be332c73a903ee88eb92b42f7b46648&woe_id=2459115\"}}}\n",
        "\n",
        "\n",
        "name : 프로젝트 이름\n",
        "\n",
        "ex) Kung Fubar\n",
        "\n",
        "photo : 사진의 정보\n",
        "\n",
        "ex) {\"key\":\"assets/039/567/041/eed695655a1b1da7aba57c76e464da43_original.png\",\"full\":\"https://ksr-ugc.imgix.net/assets/039/567/041/eed695655a1b1da7aba57c76e464da43_original.png?ixlib=rb-4.0.2&crop=faces&w=560&h=315&fit=crop&v=1672610526&auto=format&frame=1&q=92&s=77b9e747a05cfc5a1ff2224d9f1597af\",\"ed\":\"https://ksr-ugc.imgix.net/assets/039/567/041/eed695655a1b1da7aba57c76e464da43_original.png?ixlib=rb-4.0.2&crop=faces&w=352&h=198&fit=crop&v=1672610526&auto=format&frame=1&q=92&s=7146dfa070938ccde6a18ea3069c14f2\",\"med\":\"https://ksr-ugc.imgix.net/assets/039/567/041/eed695655a1b1da7aba57c76e464da43_original.png?ixlib=rb-4.0.2&crop=faces&w=272&h=153&fit=crop&v=1672610526&auto=format&frame=1&q=92&s=f3af340325ab54bf20ea8f188b8a018f\",\"little\":\"https://ksr-ugc.imgix.net/assets/039/567/041/eed695655a1b1da7aba57c76e464da43_original.png?ixlib=rb-4.0.2&crop=faces&w=208&h=117&fit=crop&v=1672610526&auto=format&frame=1&q=92&s=e07dce7f8c9faeeec70b975c9e732484\",\"small\":\"https://ksr-ugc.imgix.net/assets/039/567/041/eed695655a1b1da7aba57c76e464da43_original.png?ixlib=rb-4.0.2&crop=faces&w=160&h=90&fit=crop&v=1672610526&auto=format&frame=1&q=92&s=fdddeaaf1709a8720e411ba311230982\",\"thumb\":\"https://ksr-ugc.imgix.net/assets/039/567/041/eed695655a1b1da7aba57c76e464da43_original.png?ixlib=rb-4.0.2&crop=faces&w=48&h=27&fit=crop&v=1672610526&auto=format&frame=1&q=92&s=ff668a0fe5f03013b5c7ab67157b789c\",\"1024x576\":\"https://ksr-ugc.imgix.net/assets/039/567/041/eed695655a1b1da7aba57c76e464da43_original.png?ixlib=rb-4.0.2&crop=faces&w=1024&h=576&fit=crop&v=1672610526&auto=format&frame=1&q=92&s=359973544eca2491faffa865d6ba7444\",\"1536x864\":\"https://ksr-ugc.imgix.net/assets/039/567/041/eed695655a1b1da7aba57c76e464da43_original.png?ixlib=rb-4.0.2&crop=faces&w=1552&h=873&fit=crop&v=1672610526&auto=format&frame=1&q=92&s=48c3f141ceed55d2ba327a4b8738a952\"}\n",
        "\n",
        "\n",
        "pledged : 펀딩된 금액\n",
        "\n",
        "ex) 619.0\n",
        "\n",
        "profile : 프로젝트 프로필\n",
        "ex) {\"id\":4534078,\"project_id\":4534078,\"state\":\"inactive\",\"state_changed_at\":1672609702,\"name\":null,\"blurb\":null,\"background_color\":null,\"text_color\":null,\"link_background_color\":null,\"link_text_color\":null,\"link_text\":null,\"link_url\":null,\"show_feature_image\":false,\"background_image_opacity\":0.8,\"should_show_feature_image_section\":true,\"feature_image_attributes\":{\"image_urls\":{\"default\":\"https://ksr-ugc.imgix.net/assets/039/567/041/eed695655a1b1da7aba57c76e464da43_original.png?ixlib=rb-4.0.2&crop=faces&w=1552&h=873&fit=crop&v=1672610526&auto=format&frame=1&q=92&s=48c3f141ceed55d2ba327a4b8738a952\",\"baseball_card\":\"https://ksr-ugc.imgix.net/assets/039/567/041/eed695655a1b1da7aba57c76e464da43_original.png?ixlib=rb-4.0.2&crop=faces&w=560&h=315&fit=crop&v=1672610526&auto=format&frame=1&q=92&s=77b9e747a05cfc5a1ff2224d9f1597af\"}}}\n",
        "\n",
        "\n",
        "slug : name과 거의 동일\n",
        "\n",
        "ex) kung-fubar\n",
        "\n",
        "source_url : url\n",
        "\n",
        "ex) https://www.kickstarter.com/discover/categories/film%20&%20video/comedy\n",
        "\n",
        "spotlight : Kickstarter에 의해 홍보되었는지\n",
        "\n",
        "ex) False\n",
        "\n",
        "staff_pick : spotlight와 동일\n",
        "\n",
        "ex) False\n",
        "\n",
        "state : 프로젝트의 현재 상태('live', 'submitted', 'suspended', 'successful', 'started', 'failed', 'canceled')\n",
        "\n",
        "ex) live\n",
        "\n",
        "state_changed_at : state가 변한 날짜\n",
        "\n",
        "ex) 1672643028\n",
        "\n",
        "static_usd_rate : usd 기준 정적 환율\n",
        "\n",
        "ex) 1.0\n",
        "\n",
        "urls : 프로젝트의 주소\n",
        "\n",
        "ex) {\"web\":{\"project\":\"https://www.kickstarter.com/projects/michaeljkospiah/kung-fubar?ref=discovery_category_newest\",\"rewards\":\"https://www.kickstarter.com/projects/michaeljkospiah/kung-fubar/rewards\"}}\n",
        "\n",
        "\n",
        "usd_exchange_rate : usd 기준 환율\n",
        "\n",
        "ex) 1.0\n",
        "\n",
        "usd_pledged : usd 기준 펀딩된 금액\n",
        "\n",
        "ex) 619.0\n",
        "\n",
        "usd_type : 국제 달러여부\n",
        "\n",
        "ex) international\n"
      ],
      "metadata": {
        "id": "m0Qskb6tMz1l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "예상 타겟 : is_starrable(True, False), state('live', 'submitted', 'suspended', 'successful', 'started', 'failed', 'canceled')"
      ],
      "metadata": {
        "id": "FDYF23fRNOuN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터 정제 과정에서 drop할 특성 : blurb(설명문), creator(키 값), currency_symbol(기호), currency_trailing_code(용도 불명), country_displayable_name(country 컬럼으로 충분), disable_communication(용도 불명), id(키 값), name(유니크), photo(크롤된 사진 정보), profile(크롤된 프로필 정보), slug(유니크), source_url(크롤된 url), urls(크롤된 url), usd_type(usd에 한정된 특성)"
      ],
      "metadata": {
        "id": "jVOl9P3aNc8R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "애매한 특성 : created_at, daedline, launched_at, state_changed_at - 날짜를 사용해 유의미한 정보를 끌어낼 수 있을 것 같지만 데이터가 해석 불가능한 상태\n",
        "\n",
        "돈 관련 특성들 : 정확히 알고 있는 분야가 아니기 때문에 조정이 필요."
      ],
      "metadata": {
        "id": "0uIAZgR3pb8n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "L9R2QPZKjisQ",
        "outputId": "0655ce49-1084-4415-8ffa-ffa31a289b69"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      backers_count                                              blurb  \\\n",
              "0                12  A kung fu master gets canceled for defeating a...   \n",
              "1                 9  A black dramady short film about 3 unsuspectin...   \n",
              "2                12  A mockumentary short film that follows the gra...   \n",
              "3                46  A darkly humorous look at one man's struggle i...   \n",
              "4                 2  A comedy based on UK retail in a gaming and el...   \n",
              "...             ...                                                ...   \n",
              "3654             16  The First Ever Giardiniera Cookbook written by...   \n",
              "3655              8  I'm going to write a new Cookbook with all the...   \n",
              "3656              8  The cookbook about food and enjoyment. Written...   \n",
              "3657              1  Ein Online-Kochbuch mit Rezepten von einer Ern...   \n",
              "3658              3     “ Unlocking the crispy fried chicken secrets ”   \n",
              "\n",
              "                                               category  \\\n",
              "0     {\"id\":292,\"name\":\"Comedy\",\"analytics_name\":\"Co...   \n",
              "1     {\"id\":292,\"name\":\"Comedy\",\"analytics_name\":\"Co...   \n",
              "2     {\"id\":292,\"name\":\"Comedy\",\"analytics_name\":\"Co...   \n",
              "3     {\"id\":292,\"name\":\"Comedy\",\"analytics_name\":\"Co...   \n",
              "4     {\"id\":292,\"name\":\"Comedy\",\"analytics_name\":\"Co...   \n",
              "...                                                 ...   \n",
              "3654  {\"id\":306,\"name\":\"Cookbooks\",\"analytics_name\":...   \n",
              "3655  {\"id\":306,\"name\":\"Cookbooks\",\"analytics_name\":...   \n",
              "3656  {\"id\":306,\"name\":\"Cookbooks\",\"analytics_name\":...   \n",
              "3657  {\"id\":306,\"name\":\"Cookbooks\",\"analytics_name\":...   \n",
              "3658  {\"id\":306,\"name\":\"Cookbooks\",\"analytics_name\":...   \n",
              "\n",
              "      converted_pledged_amount country country_displayable_name  created_at  \\\n",
              "0                        619.0      US        the United States  1672609702   \n",
              "1                        431.0      GB       the United Kingdom  1667319103   \n",
              "2                        626.0      US        the United States  1671919424   \n",
              "3                       7052.0      US        the United States  1671565688   \n",
              "4                         19.0      GB       the United Kingdom  1670767302   \n",
              "...                        ...     ...                      ...         ...   \n",
              "3654                     715.0      US        the United States  1426388281   \n",
              "3655                     326.0      IT                    Italy  1542880403   \n",
              "3656                     284.0      NO                   Norway  1540822832   \n",
              "3657                       1.0      DE                  Germany  1542541998   \n",
              "3658                      89.0      SE                   Sweden  1541763202   \n",
              "\n",
              "                                                creator currency  \\\n",
              "0     {\"id\":584593596,\"name\":\"Michael J Kospiah\",\"sl...      USD   \n",
              "1     {\"id\":461556119,\"name\":\"Oscar Saunders\",\"slug\"...      GBP   \n",
              "2     {\"id\":357438630,\"name\":\"LeMieux Studios\",\"slug...      USD   \n",
              "3     {\"id\":696286874,\"name\":\"Lexi Sloan\",\"slug\":\"sl...      USD   \n",
              "4     {\"id\":62629582,\"name\":\"JTG Productions\",\"is_re...      GBP   \n",
              "...                                                 ...      ...   \n",
              "3654  {\"id\":702866505,\"name\":\"Josh Downey\",\"slug\":\"c...      USD   \n",
              "3655  {\"id\":222858142,\"name\":\"Giacomo Zangrando\",\"is...      EUR   \n",
              "3656  {\"id\":1731681397,\"name\":\"Silje Merethe Fossnes...      NOK   \n",
              "3657  {\"id\":470448202,\"name\":\"Sven Leisten (deleted)...      EUR   \n",
              "3658  {\"id\":175391867,\"name\":\"Peter Jensen\",\"is_regi...      SEK   \n",
              "\n",
              "     currency_symbol  ...                                         source_url  \\\n",
              "0                  $  ...  https://www.kickstarter.com/discover/categorie...   \n",
              "1                  £  ...  https://www.kickstarter.com/discover/categorie...   \n",
              "2                  $  ...  https://www.kickstarter.com/discover/categorie...   \n",
              "3                  $  ...  https://www.kickstarter.com/discover/categorie...   \n",
              "4                  £  ...  https://www.kickstarter.com/discover/categorie...   \n",
              "...              ...  ...                                                ...   \n",
              "3654               $  ...  https://www.kickstarter.com/discover/categorie...   \n",
              "3655               €  ...  https://www.kickstarter.com/discover/categorie...   \n",
              "3656              kr  ...  https://www.kickstarter.com/discover/categorie...   \n",
              "3657               €  ...  https://www.kickstarter.com/discover/categorie...   \n",
              "3658              kr  ...  https://www.kickstarter.com/discover/categorie...   \n",
              "\n",
              "     spotlight  staff_pick   state  state_changed_at  static_usd_rate  \\\n",
              "0        False       False    live        1672643028         1.000000   \n",
              "1        False       False    live        1672504516         1.204512   \n",
              "2        False       False    live        1671952947         1.000000   \n",
              "3        False       False    live        1671656810         1.000000   \n",
              "4        False       False    live        1671316210         1.221417   \n",
              "...        ...         ...     ...               ...              ...   \n",
              "3654     False       False  failed        1545198600         1.000000   \n",
              "3655     False       False  failed        1545476341         1.137739   \n",
              "3656     False       False  failed        1544375058         0.118492   \n",
              "3657     False       False  failed        1545138641         1.142054   \n",
              "3658     False       False  failed        1544771166         0.109642   \n",
              "\n",
              "                                                   urls  usd_exchange_rate  \\\n",
              "0     {\"web\":{\"project\":\"https://www.kickstarter.com...           1.000000   \n",
              "1     {\"web\":{\"project\":\"https://www.kickstarter.com...           1.199223   \n",
              "2     {\"web\":{\"project\":\"https://www.kickstarter.com...           1.000000   \n",
              "3     {\"web\":{\"project\":\"https://www.kickstarter.com...           1.000000   \n",
              "4     {\"web\":{\"project\":\"https://www.kickstarter.com...           1.199223   \n",
              "...                                                 ...                ...   \n",
              "3654  {\"web\":{\"project\":\"https://www.kickstarter.com...           1.000000   \n",
              "3655  {\"web\":{\"project\":\"https://www.kickstarter.com...           1.137050   \n",
              "3656  {\"web\":{\"project\":\"https://www.kickstarter.com...           0.117556   \n",
              "3657  {\"web\":{\"project\":\"https://www.kickstarter.com...           1.134776   \n",
              "3658  {\"web\":{\"project\":\"https://www.kickstarter.com...           0.110290   \n",
              "\n",
              "      usd_pledged       usd_type  \n",
              "0      619.000000  international  \n",
              "1      433.624183  international  \n",
              "2      626.000000  international  \n",
              "3     7052.000000  international  \n",
              "4       19.542677  international  \n",
              "...           ...            ...  \n",
              "3654   715.000000       domestic  \n",
              "3655   326.531170       domestic  \n",
              "3656   286.513269       domestic  \n",
              "3657     1.142054       domestic  \n",
              "3658    88.668735       domestic  \n",
              "\n",
              "[3659 rows x 35 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-424b5127-df38-4057-a284-207f13c365f4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>backers_count</th>\n",
              "      <th>blurb</th>\n",
              "      <th>category</th>\n",
              "      <th>converted_pledged_amount</th>\n",
              "      <th>country</th>\n",
              "      <th>country_displayable_name</th>\n",
              "      <th>created_at</th>\n",
              "      <th>creator</th>\n",
              "      <th>currency</th>\n",
              "      <th>currency_symbol</th>\n",
              "      <th>...</th>\n",
              "      <th>source_url</th>\n",
              "      <th>spotlight</th>\n",
              "      <th>staff_pick</th>\n",
              "      <th>state</th>\n",
              "      <th>state_changed_at</th>\n",
              "      <th>static_usd_rate</th>\n",
              "      <th>urls</th>\n",
              "      <th>usd_exchange_rate</th>\n",
              "      <th>usd_pledged</th>\n",
              "      <th>usd_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12</td>\n",
              "      <td>A kung fu master gets canceled for defeating a...</td>\n",
              "      <td>{\"id\":292,\"name\":\"Comedy\",\"analytics_name\":\"Co...</td>\n",
              "      <td>619.0</td>\n",
              "      <td>US</td>\n",
              "      <td>the United States</td>\n",
              "      <td>1672609702</td>\n",
              "      <td>{\"id\":584593596,\"name\":\"Michael J Kospiah\",\"sl...</td>\n",
              "      <td>USD</td>\n",
              "      <td>$</td>\n",
              "      <td>...</td>\n",
              "      <td>https://www.kickstarter.com/discover/categorie...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>live</td>\n",
              "      <td>1672643028</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>{\"web\":{\"project\":\"https://www.kickstarter.com...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>619.000000</td>\n",
              "      <td>international</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9</td>\n",
              "      <td>A black dramady short film about 3 unsuspectin...</td>\n",
              "      <td>{\"id\":292,\"name\":\"Comedy\",\"analytics_name\":\"Co...</td>\n",
              "      <td>431.0</td>\n",
              "      <td>GB</td>\n",
              "      <td>the United Kingdom</td>\n",
              "      <td>1667319103</td>\n",
              "      <td>{\"id\":461556119,\"name\":\"Oscar Saunders\",\"slug\"...</td>\n",
              "      <td>GBP</td>\n",
              "      <td>£</td>\n",
              "      <td>...</td>\n",
              "      <td>https://www.kickstarter.com/discover/categorie...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>live</td>\n",
              "      <td>1672504516</td>\n",
              "      <td>1.204512</td>\n",
              "      <td>{\"web\":{\"project\":\"https://www.kickstarter.com...</td>\n",
              "      <td>1.199223</td>\n",
              "      <td>433.624183</td>\n",
              "      <td>international</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12</td>\n",
              "      <td>A mockumentary short film that follows the gra...</td>\n",
              "      <td>{\"id\":292,\"name\":\"Comedy\",\"analytics_name\":\"Co...</td>\n",
              "      <td>626.0</td>\n",
              "      <td>US</td>\n",
              "      <td>the United States</td>\n",
              "      <td>1671919424</td>\n",
              "      <td>{\"id\":357438630,\"name\":\"LeMieux Studios\",\"slug...</td>\n",
              "      <td>USD</td>\n",
              "      <td>$</td>\n",
              "      <td>...</td>\n",
              "      <td>https://www.kickstarter.com/discover/categorie...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>live</td>\n",
              "      <td>1671952947</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>{\"web\":{\"project\":\"https://www.kickstarter.com...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>626.000000</td>\n",
              "      <td>international</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>46</td>\n",
              "      <td>A darkly humorous look at one man's struggle i...</td>\n",
              "      <td>{\"id\":292,\"name\":\"Comedy\",\"analytics_name\":\"Co...</td>\n",
              "      <td>7052.0</td>\n",
              "      <td>US</td>\n",
              "      <td>the United States</td>\n",
              "      <td>1671565688</td>\n",
              "      <td>{\"id\":696286874,\"name\":\"Lexi Sloan\",\"slug\":\"sl...</td>\n",
              "      <td>USD</td>\n",
              "      <td>$</td>\n",
              "      <td>...</td>\n",
              "      <td>https://www.kickstarter.com/discover/categorie...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>live</td>\n",
              "      <td>1671656810</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>{\"web\":{\"project\":\"https://www.kickstarter.com...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>7052.000000</td>\n",
              "      <td>international</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>A comedy based on UK retail in a gaming and el...</td>\n",
              "      <td>{\"id\":292,\"name\":\"Comedy\",\"analytics_name\":\"Co...</td>\n",
              "      <td>19.0</td>\n",
              "      <td>GB</td>\n",
              "      <td>the United Kingdom</td>\n",
              "      <td>1670767302</td>\n",
              "      <td>{\"id\":62629582,\"name\":\"JTG Productions\",\"is_re...</td>\n",
              "      <td>GBP</td>\n",
              "      <td>£</td>\n",
              "      <td>...</td>\n",
              "      <td>https://www.kickstarter.com/discover/categorie...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>live</td>\n",
              "      <td>1671316210</td>\n",
              "      <td>1.221417</td>\n",
              "      <td>{\"web\":{\"project\":\"https://www.kickstarter.com...</td>\n",
              "      <td>1.199223</td>\n",
              "      <td>19.542677</td>\n",
              "      <td>international</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3654</th>\n",
              "      <td>16</td>\n",
              "      <td>The First Ever Giardiniera Cookbook written by...</td>\n",
              "      <td>{\"id\":306,\"name\":\"Cookbooks\",\"analytics_name\":...</td>\n",
              "      <td>715.0</td>\n",
              "      <td>US</td>\n",
              "      <td>the United States</td>\n",
              "      <td>1426388281</td>\n",
              "      <td>{\"id\":702866505,\"name\":\"Josh Downey\",\"slug\":\"c...</td>\n",
              "      <td>USD</td>\n",
              "      <td>$</td>\n",
              "      <td>...</td>\n",
              "      <td>https://www.kickstarter.com/discover/categorie...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>failed</td>\n",
              "      <td>1545198600</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>{\"web\":{\"project\":\"https://www.kickstarter.com...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>715.000000</td>\n",
              "      <td>domestic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3655</th>\n",
              "      <td>8</td>\n",
              "      <td>I'm going to write a new Cookbook with all the...</td>\n",
              "      <td>{\"id\":306,\"name\":\"Cookbooks\",\"analytics_name\":...</td>\n",
              "      <td>326.0</td>\n",
              "      <td>IT</td>\n",
              "      <td>Italy</td>\n",
              "      <td>1542880403</td>\n",
              "      <td>{\"id\":222858142,\"name\":\"Giacomo Zangrando\",\"is...</td>\n",
              "      <td>EUR</td>\n",
              "      <td>€</td>\n",
              "      <td>...</td>\n",
              "      <td>https://www.kickstarter.com/discover/categorie...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>failed</td>\n",
              "      <td>1545476341</td>\n",
              "      <td>1.137739</td>\n",
              "      <td>{\"web\":{\"project\":\"https://www.kickstarter.com...</td>\n",
              "      <td>1.137050</td>\n",
              "      <td>326.531170</td>\n",
              "      <td>domestic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3656</th>\n",
              "      <td>8</td>\n",
              "      <td>The cookbook about food and enjoyment. Written...</td>\n",
              "      <td>{\"id\":306,\"name\":\"Cookbooks\",\"analytics_name\":...</td>\n",
              "      <td>284.0</td>\n",
              "      <td>NO</td>\n",
              "      <td>Norway</td>\n",
              "      <td>1540822832</td>\n",
              "      <td>{\"id\":1731681397,\"name\":\"Silje Merethe Fossnes...</td>\n",
              "      <td>NOK</td>\n",
              "      <td>kr</td>\n",
              "      <td>...</td>\n",
              "      <td>https://www.kickstarter.com/discover/categorie...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>failed</td>\n",
              "      <td>1544375058</td>\n",
              "      <td>0.118492</td>\n",
              "      <td>{\"web\":{\"project\":\"https://www.kickstarter.com...</td>\n",
              "      <td>0.117556</td>\n",
              "      <td>286.513269</td>\n",
              "      <td>domestic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3657</th>\n",
              "      <td>1</td>\n",
              "      <td>Ein Online-Kochbuch mit Rezepten von einer Ern...</td>\n",
              "      <td>{\"id\":306,\"name\":\"Cookbooks\",\"analytics_name\":...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>DE</td>\n",
              "      <td>Germany</td>\n",
              "      <td>1542541998</td>\n",
              "      <td>{\"id\":470448202,\"name\":\"Sven Leisten (deleted)...</td>\n",
              "      <td>EUR</td>\n",
              "      <td>€</td>\n",
              "      <td>...</td>\n",
              "      <td>https://www.kickstarter.com/discover/categorie...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>failed</td>\n",
              "      <td>1545138641</td>\n",
              "      <td>1.142054</td>\n",
              "      <td>{\"web\":{\"project\":\"https://www.kickstarter.com...</td>\n",
              "      <td>1.134776</td>\n",
              "      <td>1.142054</td>\n",
              "      <td>domestic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3658</th>\n",
              "      <td>3</td>\n",
              "      <td>“ Unlocking the crispy fried chicken secrets ”</td>\n",
              "      <td>{\"id\":306,\"name\":\"Cookbooks\",\"analytics_name\":...</td>\n",
              "      <td>89.0</td>\n",
              "      <td>SE</td>\n",
              "      <td>Sweden</td>\n",
              "      <td>1541763202</td>\n",
              "      <td>{\"id\":175391867,\"name\":\"Peter Jensen\",\"is_regi...</td>\n",
              "      <td>SEK</td>\n",
              "      <td>kr</td>\n",
              "      <td>...</td>\n",
              "      <td>https://www.kickstarter.com/discover/categorie...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>failed</td>\n",
              "      <td>1544771166</td>\n",
              "      <td>0.109642</td>\n",
              "      <td>{\"web\":{\"project\":\"https://www.kickstarter.com...</td>\n",
              "      <td>0.110290</td>\n",
              "      <td>88.668735</td>\n",
              "      <td>domestic</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3659 rows × 35 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-424b5127-df38-4057-a284-207f13c365f4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-424b5127-df38-4057-a284-207f13c365f4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-424b5127-df38-4057-a284-207f13c365f4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kick = pd.concat([df1, df2, df3])"
      ],
      "metadata": {
        "id": "Y6wnct3-PEo2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kick.drop(columns=['blurb', 'creator', 'currency_symbol', 'currency_trailing_code', 'country_displayable_name', 'disable_communication', 'id', 'name', 'photo', 'profile', 'slug', 'source_url', 'urls', 'usd_type', 'created_at', 'deadline', 'launched_at', 'state_changed_at', 'fx_rate', 'current_currency', 'usd_exchange_rate', 'static_usd_rate'], inplace=True)"
      ],
      "metadata": {
        "id": "iwlzsMhJPyCW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kick.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ErXqfROsjzI",
        "outputId": "37cc89ea-dae4-4c2b-ebb8-262c8561d3d2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "backers_count                 0\n",
              "category                      0\n",
              "converted_pledged_amount    334\n",
              "country                       0\n",
              "currency                      0\n",
              "goal                          0\n",
              "is_starrable                  0\n",
              "location                      8\n",
              "pledged                       0\n",
              "spotlight                     0\n",
              "staff_pick                    0\n",
              "state                         0\n",
              "usd_pledged                 334\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "결측치\n",
        "\n",
        "backers_count                 0\n",
        "\n",
        "category                      0\n",
        "\n",
        "converted_pledged_amount    334\n",
        "\n",
        "country                       0\n",
        "\n",
        "country_displayable_name      0\n",
        "\n",
        "currency                      0\n",
        "\n",
        "current_currency              0\n",
        "\n",
        "fx_rate                       0\n",
        "\n",
        "goal                          0\n",
        "\n",
        "is_starrable                  0\n",
        "\n",
        "location                      8\n",
        "\n",
        "pledged                       0\n",
        "\n",
        "spotlight                     0\n",
        "\n",
        "staff_pick                    0\n",
        "\n",
        "state                         0\n",
        "\n",
        "static_usd_rate               0\n",
        "\n",
        "usd_exchange_rate           334\n",
        "\n",
        "usd_pledged                 334\n",
        "\n",
        "\n",
        "지역과 약정(펀딩)의 결측치는 임의로 채우기 힘든 결측치 -> 삭제"
      ],
      "metadata": {
        "id": "yIN-aQxtwJx5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kick.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "R83gqFJywU06"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "JSON 형태가 그대로 들어온 category와 location 컬럼 정제\n",
        "\n",
        "category : 대조 결과 anlytics_name과 parent_name을 컬럼화 시킨다.\n",
        "\n",
        "parent_name에 결측치 존재 -> 동일한 카테고리의 데이터가 결측되었기 때문에 임의로 Design으로 대체\n",
        "\n",
        "location : 대조 결과 country로 대체한다. -> 추출결과 country 컬럼과 동일했기 때문에 location 컬럼을 삭제"
      ],
      "metadata": {
        "id": "UujPloB42quA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kick['category_name'] = kick['category'].str.extract('analytics_name\":\"([a-zA-z]+)')\n",
        "kick['category_parent'] = kick['category'].str.extract('parent_name\":\"([a-zA-z]+)')\n",
        "kick.drop(columns=['category', 'location'], inplace=True)\n",
        "kick['category_parent'].fillna(\"Design\", inplace=True)"
      ],
      "metadata": {
        "id": "jxsQbXJOwbWZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "환율을 적용해 usd로 변환한 컬럼인 usd_pleadged는 fx_rate나 usd_exchange_rate보다 static_usd_rate를 적용했을 때 근사치가 나옴 -> static_usd_rate를 제외한 컬럼 삭제\n",
        "\n",
        "current_currency : 현재 통화가 usd기준이라는 것은 usd_pledged에 이미 포함되어있는 정보라 판단하여 컬럼을 삭제"
      ],
      "metadata": {
        "id": "-SePENKtKrhd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kick"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "5eKEC4gJSZny",
        "outputId": "e64998d6-fcee-43df-f992-db3552648ea4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    backers_count  converted_pledged_amount country currency      goal  \\\n",
              "0              12                     619.0      US      USD     600.0   \n",
              "1               9                     431.0      GB      GBP     500.0   \n",
              "2              12                     626.0      US      USD     300.0   \n",
              "3              46                    7052.0      US      USD    8500.0   \n",
              "4               2                      19.0      GB      GBP    2000.0   \n",
              "..            ...                       ...     ...      ...       ...   \n",
              "78              1                      13.0      GB      GBP   25000.0   \n",
              "79              3                      20.0      US      USD    5000.0   \n",
              "80              2                      86.0      MX      MXN  100000.0   \n",
              "81              1                       1.0      US      USD   11000.0   \n",
              "82              0                       0.0      US      USD   25000.0   \n",
              "\n",
              "    is_starrable  pledged  spotlight  staff_pick   state  usd_pledged  \\\n",
              "0           True    619.0      False       False    live   619.000000   \n",
              "1           True    360.0      False       False    live   433.624183   \n",
              "2           True    626.0      False       False    live   626.000000   \n",
              "3           True   7052.0      False       False    live  7052.000000   \n",
              "4           True     16.0      False       False    live    19.542677   \n",
              "..           ...      ...        ...         ...     ...          ...   \n",
              "78         False     10.0      False       False  failed    13.985740   \n",
              "79         False     20.0      False       False  failed    20.000000   \n",
              "80         False   1600.0      False       False  failed    85.281968   \n",
              "81         False      1.0      False       False  failed     1.000000   \n",
              "82         False      0.0      False       False  failed     0.000000   \n",
              "\n",
              "   category_name category_parent  \n",
              "0         Comedy            Film  \n",
              "1         Comedy            Film  \n",
              "2         Comedy            Film  \n",
              "3         Comedy            Film  \n",
              "4         Comedy            Film  \n",
              "..           ...             ...  \n",
              "78      Software      Technology  \n",
              "79      Software      Technology  \n",
              "80      Software      Technology  \n",
              "81      Software      Technology  \n",
              "82      Software      Technology  \n",
              "\n",
              "[7090 rows x 13 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-45155e7f-7091-4f51-856e-80e4edb28d3b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>backers_count</th>\n",
              "      <th>converted_pledged_amount</th>\n",
              "      <th>country</th>\n",
              "      <th>currency</th>\n",
              "      <th>goal</th>\n",
              "      <th>is_starrable</th>\n",
              "      <th>pledged</th>\n",
              "      <th>spotlight</th>\n",
              "      <th>staff_pick</th>\n",
              "      <th>state</th>\n",
              "      <th>usd_pledged</th>\n",
              "      <th>category_name</th>\n",
              "      <th>category_parent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12</td>\n",
              "      <td>619.0</td>\n",
              "      <td>US</td>\n",
              "      <td>USD</td>\n",
              "      <td>600.0</td>\n",
              "      <td>True</td>\n",
              "      <td>619.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>live</td>\n",
              "      <td>619.000000</td>\n",
              "      <td>Comedy</td>\n",
              "      <td>Film</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9</td>\n",
              "      <td>431.0</td>\n",
              "      <td>GB</td>\n",
              "      <td>GBP</td>\n",
              "      <td>500.0</td>\n",
              "      <td>True</td>\n",
              "      <td>360.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>live</td>\n",
              "      <td>433.624183</td>\n",
              "      <td>Comedy</td>\n",
              "      <td>Film</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12</td>\n",
              "      <td>626.0</td>\n",
              "      <td>US</td>\n",
              "      <td>USD</td>\n",
              "      <td>300.0</td>\n",
              "      <td>True</td>\n",
              "      <td>626.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>live</td>\n",
              "      <td>626.000000</td>\n",
              "      <td>Comedy</td>\n",
              "      <td>Film</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>46</td>\n",
              "      <td>7052.0</td>\n",
              "      <td>US</td>\n",
              "      <td>USD</td>\n",
              "      <td>8500.0</td>\n",
              "      <td>True</td>\n",
              "      <td>7052.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>live</td>\n",
              "      <td>7052.000000</td>\n",
              "      <td>Comedy</td>\n",
              "      <td>Film</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>19.0</td>\n",
              "      <td>GB</td>\n",
              "      <td>GBP</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>True</td>\n",
              "      <td>16.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>live</td>\n",
              "      <td>19.542677</td>\n",
              "      <td>Comedy</td>\n",
              "      <td>Film</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>1</td>\n",
              "      <td>13.0</td>\n",
              "      <td>GB</td>\n",
              "      <td>GBP</td>\n",
              "      <td>25000.0</td>\n",
              "      <td>False</td>\n",
              "      <td>10.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>failed</td>\n",
              "      <td>13.985740</td>\n",
              "      <td>Software</td>\n",
              "      <td>Technology</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>3</td>\n",
              "      <td>20.0</td>\n",
              "      <td>US</td>\n",
              "      <td>USD</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>False</td>\n",
              "      <td>20.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>failed</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>Software</td>\n",
              "      <td>Technology</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>2</td>\n",
              "      <td>86.0</td>\n",
              "      <td>MX</td>\n",
              "      <td>MXN</td>\n",
              "      <td>100000.0</td>\n",
              "      <td>False</td>\n",
              "      <td>1600.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>failed</td>\n",
              "      <td>85.281968</td>\n",
              "      <td>Software</td>\n",
              "      <td>Technology</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>US</td>\n",
              "      <td>USD</td>\n",
              "      <td>11000.0</td>\n",
              "      <td>False</td>\n",
              "      <td>1.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>failed</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>Software</td>\n",
              "      <td>Technology</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>US</td>\n",
              "      <td>USD</td>\n",
              "      <td>25000.0</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>failed</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>Software</td>\n",
              "      <td>Technology</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7090 rows × 13 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-45155e7f-7091-4f51-856e-80e4edb28d3b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-45155e7f-7091-4f51-856e-80e4edb28d3b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-45155e7f-7091-4f51-856e-80e4edb28d3b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "static_usd_rate 또한 usd_pledged에 이미 포함되어있느 정보로 판단된다. -> 삭제"
      ],
      "metadata": {
        "id": "L1YrT8P5Lcr2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kick.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EA1xivR3HSmY",
        "outputId": "69478844-8bca-437e-ba71-80454561295e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 7090 entries, 0 to 82\n",
            "Data columns (total 13 columns):\n",
            " #   Column                    Non-Null Count  Dtype  \n",
            "---  ------                    --------------  -----  \n",
            " 0   backers_count             7090 non-null   int64  \n",
            " 1   converted_pledged_amount  7090 non-null   float64\n",
            " 2   country                   7090 non-null   object \n",
            " 3   currency                  7090 non-null   object \n",
            " 4   goal                      7090 non-null   float64\n",
            " 5   is_starrable              7090 non-null   bool   \n",
            " 6   pledged                   7090 non-null   float64\n",
            " 7   spotlight                 7090 non-null   bool   \n",
            " 8   staff_pick                7090 non-null   bool   \n",
            " 9   state                     7090 non-null   object \n",
            " 10  usd_pledged               7090 non-null   float64\n",
            " 11  category_name             7090 non-null   object \n",
            " 12  category_parent           7090 non-null   object \n",
            "dtypes: bool(3), float64(4), int64(1), object(5)\n",
            "memory usage: 630.1+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "초기 데이터 프레임 7090x13"
      ],
      "metadata": {
        "id": "IxF2CYXWL81K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델링"
      ],
      "metadata": {
        "id": "71VIkbQEMmjl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install category_encoders\n",
        "!pip3 install eli5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "baRPPobbUjgM",
        "outputId": "d9fdedc3-7c4a-46c0-a56f-eba915e255c9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting category_encoders\n",
            "  Downloading category_encoders-2.6.0-py2.py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.2/81.2 KB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.8/dist-packages (from category_encoders) (1.3.5)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from category_encoders) (1.7.3)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.8/dist-packages (from category_encoders) (1.0.2)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.8/dist-packages (from category_encoders) (0.12.2)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.8/dist-packages (from category_encoders) (0.5.3)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.8/dist-packages (from category_encoders) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0.5->category_encoders) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from patsy>=0.5.1->category_encoders) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.20.0->category_encoders) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.20.0->category_encoders) (3.1.0)\n",
            "Installing collected packages: category_encoders\n",
            "Successfully installed category_encoders-2.6.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting eli5\n",
            "  Downloading eli5-0.13.0.tar.gz (216 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.2/216.2 KB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: attrs>17.1.0 in /usr/local/lib/python3.8/dist-packages (from eli5) (22.2.0)\n",
            "Collecting jinja2>=3.0.0\n",
            "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/133.1 KB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from eli5) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from eli5) (1.7.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from eli5) (1.15.0)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.8/dist-packages (from eli5) (1.0.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.8/dist-packages (from eli5) (0.10.1)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.8/dist-packages (from eli5) (0.8.10)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2>=3.0.0->eli5) (2.0.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.20->eli5) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.20->eli5) (3.1.0)\n",
            "Building wheels for collected packages: eli5\n",
            "  Building wheel for eli5 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for eli5: filename=eli5-0.13.0-py2.py3-none-any.whl size=107748 sha256=93ef69c174a2b863970c1e1fd6bd0adc82af1117305b839c81b1e3f189f8333e\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/ac/25/ffcd87ef8f9b1eec324fdf339359be71f22612459d8c75d89c\n",
            "Successfully built eli5\n",
            "Installing collected packages: jinja2, eli5\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 2.11.3\n",
            "    Uninstalling Jinja2-2.11.3:\n",
            "      Successfully uninstalled Jinja2-2.11.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "notebook 5.7.16 requires jinja2<=3.0.0, but you have jinja2 3.1.2 which is incompatible.\n",
            "flask 1.1.4 requires Jinja2<3.0,>=2.10.1, but you have jinja2 3.1.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed eli5-0.13.0 jinja2-3.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 라이브러리\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import seaborn as sns\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from category_encoders import OrdinalEncoder\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import graphviz\n",
        "from sklearn.tree import export_graphviz\n",
        "import matplotlib.pyplot as plt\n",
        "from xgboost import XGBClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import eli5\n",
        "from eli5.sklearn import PermutationImportance\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "metadata": {
        "id": "13JK9CjjNl_v"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target = 'is_starrable'\n",
        "features = kick.drop(columns=target).columns.to_list()"
      ],
      "metadata": {
        "id": "uM02cUqyNLPa"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train, val = train_test_split(\n",
        "    kick, train_size=0.80, test_size=0.20, stratify=kick[target], random_state=2\n",
        ")\n",
        "\n",
        "X_train = train[features]\n",
        "y_train = train[target]\n",
        "X_val = val[features]\n",
        "y_val = val[target]"
      ],
      "metadata": {
        "id": "r53Esrr2NkVq"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Baseline Score:\", kick[target].value_counts(normalize=True).max())\n",
        "#비현실적인 수치의 기준모델"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbvIigqtPxCy",
        "outputId": "bd5df996-6bd6-4704-d758-1468b243b7ef"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline Score: 0.9588152327221439\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kick[target].value_counts(normalize=True).plot.pie(autopct=\"%.3f%%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "u2InkuFhYRd8",
        "outputId": "1c376922-0298-4a53-affd-97f180ffc6d7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f930be86a90>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kick[target].describe()\n",
        "#타겟의 분포가 치우쳐져있다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awb79v6yTaKY",
        "outputId": "4c3cea92-3d62-4825-ba75-bfdabaababf2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count      7090\n",
              "unique        2\n",
              "top       False\n",
              "freq       6798\n",
              "Name: is_starrable, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = make_pipeline(\n",
        "    OrdinalEncoder(),\n",
        "    DecisionTreeClassifier(max_depth=6, random_state=2),\n",
        ")\n",
        "pipe.fit(X_train, y_train)\n",
        "print(\"검증 정확도\", pipe.score(X_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e16Zb8PQUgaw",
        "outputId": "85e6fcc6-13b0-41bb-9e22-0286b84a5e81"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "검증 정확도 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tree = pipe.named_steps[\"decisiontreeclassifier\"]\n",
        "\n",
        "dot_data = export_graphviz(\n",
        "    tree,\n",
        "    feature_names=X_train.columns,\n",
        "    class_names=[\"False\", \"True\"],\n",
        "    filled=True,\n",
        "    proportion=True,\n",
        ")\n",
        "\n",
        "graphviz.Source(dot_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6EmGyOCEWWHY",
        "outputId": "16e93cae-27d8-4b2f-e4bd-e1ec2440c433"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.files.Source at 0x7f930bdb4250>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: Tree Pages: 1 -->\n<svg width=\"691pt\" height=\"790pt\"\n viewBox=\"0.00 0.00 690.50 790.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 786)\">\n<title>Tree</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-786 686.5,-786 686.5,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<polygon fill=\"#e68642\" stroke=\"black\" points=\"212.5,-782 65.5,-782 65.5,-699 212.5,-699 212.5,-782\"/>\n<text text-anchor=\"middle\" x=\"139\" y=\"-766.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">state &lt;= 3.5</text>\n<text text-anchor=\"middle\" x=\"139\" y=\"-751.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.079</text>\n<text text-anchor=\"middle\" x=\"139\" y=\"-736.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 100.0%</text>\n<text text-anchor=\"middle\" x=\"139\" y=\"-721.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.959, 0.041]</text>\n<text text-anchor=\"middle\" x=\"139\" y=\"-706.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = False</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<polygon fill=\"#e58139\" stroke=\"black\" points=\"122,-655.5 0,-655.5 0,-587.5 122,-587.5 122,-655.5\"/>\n<text text-anchor=\"middle\" x=\"61\" y=\"-640.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"middle\" x=\"61\" y=\"-625.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 95.8%</text>\n<text text-anchor=\"middle\" x=\"61\" y=\"-610.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1.0, 0.0]</text>\n<text text-anchor=\"middle\" x=\"61\" y=\"-595.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = False</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M111.94,-698.91C104.43,-687.65 96.28,-675.42 88.74,-664.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"91.57,-662.05 83.11,-655.67 85.75,-665.93 91.57,-662.05\"/>\n<text text-anchor=\"middle\" x=\"78.21\" y=\"-676.48\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<polygon fill=\"#3b9ee5\" stroke=\"black\" points=\"295.5,-663 140.5,-663 140.5,-580 295.5,-580 295.5,-663\"/>\n<text text-anchor=\"middle\" x=\"218\" y=\"-647.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">backers_count &lt;= 36.5</text>\n<text text-anchor=\"middle\" x=\"218\" y=\"-632.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.017</text>\n<text text-anchor=\"middle\" x=\"218\" y=\"-617.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4.2%</text>\n<text text-anchor=\"middle\" x=\"218\" y=\"-602.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.008, 0.992]</text>\n<text text-anchor=\"middle\" x=\"218\" y=\"-587.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = True</text>\n</g>\n<!-- 0&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>0&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M166.41,-698.91C172.41,-690.01 178.83,-680.51 185.03,-671.33\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"187.94,-673.27 190.64,-663.02 182.14,-669.35 187.94,-673.27\"/>\n<text text-anchor=\"middle\" x=\"195.4\" y=\"-683.86\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<polygon fill=\"#399de5\" stroke=\"black\" points=\"199.5,-536.5 82.5,-536.5 82.5,-468.5 199.5,-468.5 199.5,-536.5\"/>\n<text text-anchor=\"middle\" x=\"141\" y=\"-521.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"middle\" x=\"141\" y=\"-506.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2.8%</text>\n<text text-anchor=\"middle\" x=\"141\" y=\"-491.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.0, 1.0]</text>\n<text text-anchor=\"middle\" x=\"141\" y=\"-476.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = True</text>\n</g>\n<!-- 2&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>2&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M191.29,-579.91C183.88,-568.65 175.83,-556.42 168.38,-545.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"171.25,-543.1 162.83,-536.67 165.4,-546.94 171.25,-543.1\"/>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<polygon fill=\"#3ea0e6\" stroke=\"black\" points=\"372.5,-544 217.5,-544 217.5,-461 372.5,-461 372.5,-544\"/>\n<text text-anchor=\"middle\" x=\"295\" y=\"-528.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">backers_count &lt;= 37.5</text>\n<text text-anchor=\"middle\" x=\"295\" y=\"-513.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.051</text>\n<text text-anchor=\"middle\" x=\"295\" y=\"-498.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1.4%</text>\n<text text-anchor=\"middle\" x=\"295\" y=\"-483.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.026, 0.974]</text>\n<text text-anchor=\"middle\" x=\"295\" y=\"-468.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = True</text>\n</g>\n<!-- 2&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>2&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M244.71,-579.91C250.51,-571.1 256.7,-561.7 262.68,-552.61\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"265.76,-554.3 268.33,-544.02 259.91,-550.45 265.76,-554.3\"/>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<polygon fill=\"#e58139\" stroke=\"black\" points=\"278.5,-417.5 161.5,-417.5 161.5,-349.5 278.5,-349.5 278.5,-417.5\"/>\n<text text-anchor=\"middle\" x=\"220\" y=\"-402.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"middle\" x=\"220\" y=\"-387.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 0.0%</text>\n<text text-anchor=\"middle\" x=\"220\" y=\"-372.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1.0, 0.0]</text>\n<text text-anchor=\"middle\" x=\"220\" y=\"-357.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = False</text>\n</g>\n<!-- 4&#45;&gt;5 -->\n<g id=\"edge5\" class=\"edge\">\n<title>4&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"black\" d=\"M268.98,-460.91C261.76,-449.65 253.92,-437.42 246.67,-426.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"249.6,-424.2 241.26,-417.67 243.71,-427.97 249.6,-424.2\"/>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\">\n<title>6</title>\n<polygon fill=\"#3c9ee5\" stroke=\"black\" points=\"443.5,-425 296.5,-425 296.5,-342 443.5,-342 443.5,-425\"/>\n<text text-anchor=\"middle\" x=\"370\" y=\"-409.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">currency &lt;= 6.0</text>\n<text text-anchor=\"middle\" x=\"370\" y=\"-394.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.026</text>\n<text text-anchor=\"middle\" x=\"370\" y=\"-379.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1.3%</text>\n<text text-anchor=\"middle\" x=\"370\" y=\"-364.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.013, 0.987]</text>\n<text text-anchor=\"middle\" x=\"370\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = True</text>\n</g>\n<!-- 4&#45;&gt;6 -->\n<g id=\"edge6\" class=\"edge\">\n<title>4&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"black\" d=\"M321.02,-460.91C326.66,-452.1 332.69,-442.7 338.52,-433.61\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"341.57,-435.33 344.03,-425.02 335.68,-431.55 341.57,-435.33\"/>\n</g>\n<!-- 7 -->\n<g id=\"node8\" class=\"node\">\n<title>7</title>\n<polygon fill=\"#399de5\" stroke=\"black\" points=\"326.5,-298.5 209.5,-298.5 209.5,-230.5 326.5,-230.5 326.5,-298.5\"/>\n<text text-anchor=\"middle\" x=\"268\" y=\"-283.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"middle\" x=\"268\" y=\"-268.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1.2%</text>\n<text text-anchor=\"middle\" x=\"268\" y=\"-253.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.0, 1.0]</text>\n<text text-anchor=\"middle\" x=\"268\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = True</text>\n</g>\n<!-- 6&#45;&gt;7 -->\n<g id=\"edge7\" class=\"edge\">\n<title>6&#45;&gt;7</title>\n<path fill=\"none\" stroke=\"black\" d=\"M334.61,-341.91C324.61,-330.43 313.72,-317.94 303.69,-306.44\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"306.12,-303.9 296.91,-298.67 300.85,-308.5 306.12,-303.9\"/>\n</g>\n<!-- 8 -->\n<g id=\"node9\" class=\"node\">\n<title>8</title>\n<polygon fill=\"#4fa8e8\" stroke=\"black\" points=\"601.5,-306 344.5,-306 344.5,-223 601.5,-223 601.5,-306\"/>\n<text text-anchor=\"middle\" x=\"473\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">converted_pledged_amount &lt;= 17659.5</text>\n<text text-anchor=\"middle\" x=\"473\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.18</text>\n<text text-anchor=\"middle\" x=\"473\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 0.2%</text>\n<text text-anchor=\"middle\" x=\"473\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.1, 0.9]</text>\n<text text-anchor=\"middle\" x=\"473\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = True</text>\n</g>\n<!-- 6&#45;&gt;8 -->\n<g id=\"edge8\" class=\"edge\">\n<title>6&#45;&gt;8</title>\n<path fill=\"none\" stroke=\"black\" d=\"M405.74,-341.91C413.72,-332.83 422.27,-323.12 430.51,-313.77\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"433.35,-315.84 437.33,-306.02 428.09,-311.21 433.35,-315.84\"/>\n</g>\n<!-- 9 -->\n<g id=\"node10\" class=\"node\">\n<title>9</title>\n<polygon fill=\"#399de5\" stroke=\"black\" points=\"447.5,-179.5 330.5,-179.5 330.5,-111.5 447.5,-111.5 447.5,-179.5\"/>\n<text text-anchor=\"middle\" x=\"389\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"middle\" x=\"389\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 0.1%</text>\n<text text-anchor=\"middle\" x=\"389\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.0, 1.0]</text>\n<text text-anchor=\"middle\" x=\"389\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = True</text>\n</g>\n<!-- 8&#45;&gt;9 -->\n<g id=\"edge9\" class=\"edge\">\n<title>8&#45;&gt;9</title>\n<path fill=\"none\" stroke=\"black\" d=\"M443.86,-222.91C435.78,-211.65 426.99,-199.42 418.87,-188.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"421.49,-185.75 412.81,-179.67 415.8,-189.83 421.49,-185.75\"/>\n</g>\n<!-- 10 -->\n<g id=\"node11\" class=\"node\">\n<title>10</title>\n<polygon fill=\"#ffffff\" stroke=\"black\" points=\"648,-187 466,-187 466,-104 648,-104 648,-187\"/>\n<text text-anchor=\"middle\" x=\"557\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">usd_pledged &lt;= 20466.879</text>\n<text text-anchor=\"middle\" x=\"557\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"middle\" x=\"557\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 0.0%</text>\n<text text-anchor=\"middle\" x=\"557\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.5, 0.5]</text>\n<text text-anchor=\"middle\" x=\"557\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = False</text>\n</g>\n<!-- 8&#45;&gt;10 -->\n<g id=\"edge10\" class=\"edge\">\n<title>8&#45;&gt;10</title>\n<path fill=\"none\" stroke=\"black\" d=\"M502.14,-222.91C508.53,-214.01 515.35,-204.51 521.94,-195.33\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"524.92,-197.19 527.91,-187.02 519.23,-193.1 524.92,-197.19\"/>\n</g>\n<!-- 11 -->\n<g id=\"node12\" class=\"node\">\n<title>11</title>\n<polygon fill=\"#e58139\" stroke=\"black\" points=\"547.5,-68 430.5,-68 430.5,0 547.5,0 547.5,-68\"/>\n<text text-anchor=\"middle\" x=\"489\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"middle\" x=\"489\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 0.0%</text>\n<text text-anchor=\"middle\" x=\"489\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1.0, 0.0]</text>\n<text text-anchor=\"middle\" x=\"489\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = False</text>\n</g>\n<!-- 10&#45;&gt;11 -->\n<g id=\"edge11\" class=\"edge\">\n<title>10&#45;&gt;11</title>\n<path fill=\"none\" stroke=\"black\" d=\"M531.68,-103.73C526.24,-94.97 520.49,-85.7 515.02,-76.91\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"517.93,-74.95 509.68,-68.3 511.98,-78.64 517.93,-74.95\"/>\n</g>\n<!-- 12 -->\n<g id=\"node13\" class=\"node\">\n<title>12</title>\n<polygon fill=\"#399de5\" stroke=\"black\" points=\"682.5,-68 565.5,-68 565.5,0 682.5,0 682.5,-68\"/>\n<text text-anchor=\"middle\" x=\"624\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"middle\" x=\"624\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 0.0%</text>\n<text text-anchor=\"middle\" x=\"624\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.0, 1.0]</text>\n<text text-anchor=\"middle\" x=\"624\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = True</text>\n</g>\n<!-- 10&#45;&gt;12 -->\n<g id=\"edge12\" class=\"edge\">\n<title>10&#45;&gt;12</title>\n<path fill=\"none\" stroke=\"black\" d=\"M581.95,-103.73C587.31,-94.97 592.98,-85.7 598.36,-76.91\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"601.39,-78.66 603.62,-68.3 595.42,-75 601.39,-78.66\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "state를 기준으로 대부분의 샘플이 갈려버림"
      ],
      "metadata": {
        "id": "RkL86-JOWt8l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_drop = X_train.drop([\"state\"], axis=1)\n",
        "X_val_drop = X_val.drop([\"state\"], axis=1)"
      ],
      "metadata": {
        "id": "XglD41OiW78p"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = make_pipeline(\n",
        "    OrdinalEncoder(),\n",
        "    DecisionTreeClassifier(max_depth=6, random_state=2),\n",
        ")\n",
        "pipe.fit(X_train_drop, y_train)\n",
        "print(\"검증 정확도\", pipe.score(X_val_drop, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nr7iVQFJXDKx",
        "outputId": "dc5f9ec1-eb31-47e3-961b-dcad82d36632"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "검증 정확도 0.9901269393511989\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tree = pipe.named_steps[\"decisiontreeclassifier\"]\n",
        "\n",
        "dot_data = export_graphviz(\n",
        "    tree,\n",
        "    feature_names=X_train_drop.columns,\n",
        "    class_names=[\"False\", \"True\"],\n",
        "    filled=True,\n",
        "    proportion=True,\n",
        ")\n",
        "\n",
        "graphviz.Source(dot_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iRUJwJNRXKUQ",
        "outputId": "cde54e54-7069-4657-8fa5-b2c1b2f05336"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.files.Source at 0x7f930b908fd0>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: Tree Pages: 1 -->\n<svg width=\"1533pt\" height=\"790pt\"\n viewBox=\"0.00 0.00 1533.00 790.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 786)\">\n<title>Tree</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-786 1529,-786 1529,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<polygon fill=\"#e68642\" stroke=\"black\" points=\"1061,-782 900,-782 900,-699 1061,-699 1061,-782\"/>\n<text text-anchor=\"middle\" x=\"980.5\" y=\"-766.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">category_name &lt;= 13.5</text>\n<text text-anchor=\"middle\" x=\"980.5\" y=\"-751.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.079</text>\n<text text-anchor=\"middle\" x=\"980.5\" y=\"-736.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 100.0%</text>\n<text text-anchor=\"middle\" x=\"980.5\" y=\"-721.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.959, 0.041]</text>\n<text text-anchor=\"middle\" x=\"980.5\" y=\"-706.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = False</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<polygon fill=\"#e68640\" stroke=\"black\" points=\"974,-663 817,-663 817,-580 974,-580 974,-663\"/>\n<text text-anchor=\"middle\" x=\"895.5\" y=\"-647.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">category_parent &lt;= 4.5</text>\n<text text-anchor=\"middle\" x=\"895.5\" y=\"-632.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.069</text>\n<text text-anchor=\"middle\" x=\"895.5\" y=\"-617.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 99.4%</text>\n<text text-anchor=\"middle\" x=\"895.5\" y=\"-602.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.964, 0.036]</text>\n<text text-anchor=\"middle\" x=\"895.5\" y=\"-587.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = False</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M951.01,-698.91C944.55,-690.01 937.64,-680.51 930.98,-671.33\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"933.65,-669.05 924.94,-663.02 927.98,-673.17 933.65,-669.05\"/>\n<text text-anchor=\"middle\" x=\"921.03\" y=\"-684.01\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n</g>\n<!-- 30 -->\n<g id=\"node31\" class=\"node\">\n<title>30</title>\n<polygon fill=\"#3fa0e6\" stroke=\"black\" points=\"1139,-663 992,-663 992,-580 1139,-580 1139,-663\"/>\n<text text-anchor=\"middle\" x=\"1065.5\" y=\"-647.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">spotlight &lt;= 0.5</text>\n<text text-anchor=\"middle\" x=\"1065.5\" y=\"-632.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.061</text>\n<text text-anchor=\"middle\" x=\"1065.5\" y=\"-617.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 0.6%</text>\n<text text-anchor=\"middle\" x=\"1065.5\" y=\"-602.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.031, 0.969]</text>\n<text text-anchor=\"middle\" x=\"1065.5\" y=\"-587.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = True</text>\n</g>\n<!-- 0&#45;&gt;30 -->\n<g id=\"edge30\" class=\"edge\">\n<title>0&#45;&gt;30</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1009.99,-698.91C1016.45,-690.01 1023.36,-680.51 1030.02,-671.33\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1033.02,-673.17 1036.06,-663.02 1027.35,-669.05 1033.02,-673.17\"/>\n<text text-anchor=\"middle\" x=\"1039.97\" y=\"-684.01\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<polygon fill=\"#e5823b\" stroke=\"black\" points=\"770.5,-544 638.5,-544 638.5,-461 770.5,-461 770.5,-544\"/>\n<text text-anchor=\"middle\" x=\"704.5\" y=\"-528.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">spotlight &lt;= 0.5</text>\n<text text-anchor=\"middle\" x=\"704.5\" y=\"-513.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.019</text>\n<text text-anchor=\"middle\" x=\"704.5\" y=\"-498.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 66.7%</text>\n<text text-anchor=\"middle\" x=\"704.5\" y=\"-483.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.99, 0.01]</text>\n<text text-anchor=\"middle\" x=\"704.5\" y=\"-468.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = False</text>\n</g>\n<!-- 1&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>1&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M829.23,-579.91C813.09,-570.02 795.7,-559.37 779.19,-549.25\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"781,-546.26 770.65,-544.02 777.35,-552.23 781,-546.26\"/>\n</g>\n<!-- 13 -->\n<g id=\"node14\" class=\"node\">\n<title>13</title>\n<polygon fill=\"#e88d4c\" stroke=\"black\" points=\"977,-544 824,-544 824,-461 977,-461 977,-544\"/>\n<text text-anchor=\"middle\" x=\"900.5\" y=\"-528.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">category_name &lt;= 7.0</text>\n<text text-anchor=\"middle\" x=\"900.5\" y=\"-513.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.163</text>\n<text text-anchor=\"middle\" x=\"900.5\" y=\"-498.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 32.8%</text>\n<text text-anchor=\"middle\" x=\"900.5\" y=\"-483.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.911, 0.089]</text>\n<text text-anchor=\"middle\" x=\"900.5\" y=\"-468.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = False</text>\n</g>\n<!-- 1&#45;&gt;13 -->\n<g id=\"edge13\" class=\"edge\">\n<title>1&#45;&gt;13</title>\n<path fill=\"none\" stroke=\"black\" d=\"M897.23,-579.91C897.59,-571.56 897.97,-562.67 898.34,-554.02\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"901.84,-554.16 898.77,-544.02 894.84,-553.86 901.84,-554.16\"/>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<polygon fill=\"#e6843d\" stroke=\"black\" points=\"621,-425 464,-425 464,-342 621,-342 621,-425\"/>\n<text text-anchor=\"middle\" x=\"542.5\" y=\"-409.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">category_parent &lt;= 3.5</text>\n<text text-anchor=\"middle\" x=\"542.5\" y=\"-394.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.04</text>\n<text text-anchor=\"middle\" x=\"542.5\" y=\"-379.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 32.3%</text>\n<text text-anchor=\"middle\" x=\"542.5\" y=\"-364.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.98, 0.02]</text>\n<text text-anchor=\"middle\" x=\"542.5\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = False</text>\n</g>\n<!-- 2&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>2&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M648.29,-460.91C634.98,-451.29 620.67,-440.95 607.01,-431.09\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"608.76,-428.04 598.61,-425.02 604.66,-433.71 608.76,-428.04\"/>\n</g>\n<!-- 12 -->\n<g id=\"node13\" class=\"node\">\n<title>12</title>\n<polygon fill=\"#e58139\" stroke=\"black\" points=\"765.5,-417.5 643.5,-417.5 643.5,-349.5 765.5,-349.5 765.5,-417.5\"/>\n<text text-anchor=\"middle\" x=\"704.5\" y=\"-402.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"middle\" x=\"704.5\" y=\"-387.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 34.3%</text>\n<text text-anchor=\"middle\" x=\"704.5\" y=\"-372.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1.0, 0.0]</text>\n<text text-anchor=\"middle\" x=\"704.5\" y=\"-357.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = False</text>\n</g>\n<!-- 2&#45;&gt;12 -->\n<g id=\"edge12\" class=\"edge\">\n<title>2&#45;&gt;12</title>\n<path fill=\"none\" stroke=\"black\" d=\"M704.5,-460.91C704.5,-450.2 704.5,-438.62 704.5,-427.78\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"708,-427.67 704.5,-417.67 701,-427.67 708,-427.67\"/>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<polygon fill=\"#e5833c\" stroke=\"black\" points=\"465,-306 318,-306 318,-223 465,-223 465,-306\"/>\n<text text-anchor=\"middle\" x=\"391.5\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">goal &lt;= 625.0</text>\n<text text-anchor=\"middle\" x=\"391.5\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.031</text>\n<text text-anchor=\"middle\" x=\"391.5\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 32.2%</text>\n<text text-anchor=\"middle\" x=\"391.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.984, 0.016]</text>\n<text text-anchor=\"middle\" x=\"391.5\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = False</text>\n</g>\n<!-- 3&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>3&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M490.11,-341.91C477.81,-332.38 464.61,-322.15 451.99,-312.37\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"453.84,-309.38 443.8,-306.02 449.56,-314.91 453.84,-309.38\"/>\n</g>\n<!-- 11 -->\n<g id=\"node12\" class=\"node\">\n<title>11</title>\n<polygon fill=\"#399de5\" stroke=\"black\" points=\"601,-298.5 484,-298.5 484,-230.5 601,-230.5 601,-298.5\"/>\n<text text-anchor=\"middle\" x=\"542.5\" y=\"-283.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"middle\" x=\"542.5\" y=\"-268.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 0.1%</text>\n<text text-anchor=\"middle\" x=\"542.5\" y=\"-253.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.0, 1.0]</text>\n<text text-anchor=\"middle\" x=\"542.5\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = True</text>\n</g>\n<!-- 3&#45;&gt;11 -->\n<g id=\"edge11\" class=\"edge\">\n<title>3&#45;&gt;11</title>\n<path fill=\"none\" stroke=\"black\" d=\"M542.5,-341.91C542.5,-331.2 542.5,-319.62 542.5,-308.78\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"546,-308.67 542.5,-298.67 539,-308.67 546,-308.67\"/>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<polygon fill=\"#e78a48\" stroke=\"black\" points=\"297,-187 150,-187 150,-104 297,-104 297,-187\"/>\n<text text-anchor=\"middle\" x=\"223.5\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">pledged &lt;= 320.5</text>\n<text text-anchor=\"middle\" x=\"223.5\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.129</text>\n<text text-anchor=\"middle\" x=\"223.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1.3%</text>\n<text text-anchor=\"middle\" x=\"223.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.931, 0.069]</text>\n<text text-anchor=\"middle\" x=\"223.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = False</text>\n</g>\n<!-- 4&#45;&gt;5 -->\n<g id=\"edge5\" class=\"edge\">\n<title>4&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"black\" d=\"M333.21,-222.91C319.27,-213.2 304.28,-202.76 290,-192.81\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"291.89,-189.86 281.68,-187.02 287.89,-195.61 291.89,-189.86\"/>\n</g>\n<!-- 8 -->\n<g id=\"node9\" class=\"node\">\n<title>8</title>\n<polygon fill=\"#e5833c\" stroke=\"black\" points=\"468,-187 315,-187 315,-104 468,-104 468,-187\"/>\n<text text-anchor=\"middle\" x=\"391.5\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">category_name &lt;= 4.0</text>\n<text text-anchor=\"middle\" x=\"391.5\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.027</text>\n<text text-anchor=\"middle\" x=\"391.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 30.9%</text>\n<text text-anchor=\"middle\" x=\"391.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.986, 0.014]</text>\n<text text-anchor=\"middle\" x=\"391.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = False</text>\n</g>\n<!-- 4&#45;&gt;8 -->\n<g id=\"edge8\" class=\"edge\">\n<title>4&#45;&gt;8</title>\n<path fill=\"none\" stroke=\"black\" d=\"M391.5,-222.91C391.5,-214.65 391.5,-205.86 391.5,-197.3\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"395,-197.02 391.5,-187.02 388,-197.02 395,-197.02\"/>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\">\n<title>6</title>\n<polygon fill=\"#e5833c\" stroke=\"black\" points=\"147,-68 0,-68 0,0 147,0 147,-68\"/>\n<text text-anchor=\"middle\" x=\"73.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.029</text>\n<text text-anchor=\"middle\" x=\"73.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1.2%</text>\n<text text-anchor=\"middle\" x=\"73.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.985, 0.015]</text>\n<text text-anchor=\"middle\" x=\"73.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = False</text>\n</g>\n<!-- 5&#45;&gt;6 -->\n<g id=\"edge6\" class=\"edge\">\n<title>5&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"black\" d=\"M167.65,-103.73C154.53,-94.15 140.57,-83.96 127.53,-74.44\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"129.26,-71.37 119.12,-68.3 125.13,-77.02 129.26,-71.37\"/>\n</g>\n<!-- 7 -->\n<g id=\"node8\" class=\"node\">\n<title>7</title>\n<polygon fill=\"#6ab6ec\" stroke=\"black\" points=\"282,-68 165,-68 165,0 282,0 282,-68\"/>\n<text text-anchor=\"middle\" x=\"223.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.32</text>\n<text text-anchor=\"middle\" x=\"223.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 0.1%</text>\n<text text-anchor=\"middle\" x=\"223.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.2, 0.8]</text>\n<text text-anchor=\"middle\" x=\"223.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = True</text>\n</g>\n<!-- 5&#45;&gt;7 -->\n<g id=\"edge7\" class=\"edge\">\n<title>5&#45;&gt;7</title>\n<path fill=\"none\" stroke=\"black\" d=\"M223.5,-103.73C223.5,-95.52 223.5,-86.86 223.5,-78.56\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"227,-78.3 223.5,-68.3 220,-78.3 227,-78.3\"/>\n</g>\n<!-- 9 -->\n<g id=\"node10\" class=\"node\">\n<title>9</title>\n<polygon fill=\"#e6843e\" stroke=\"black\" points=\"447,-68 300,-68 300,0 447,0 447,-68\"/>\n<text text-anchor=\"middle\" x=\"373.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.044</text>\n<text text-anchor=\"middle\" x=\"373.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 15.1%</text>\n<text text-anchor=\"middle\" x=\"373.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.978, 0.022]</text>\n<text text-anchor=\"middle\" x=\"373.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = False</text>\n</g>\n<!-- 8&#45;&gt;9 -->\n<g id=\"edge9\" class=\"edge\">\n<title>8&#45;&gt;9</title>\n<path fill=\"none\" stroke=\"black\" d=\"M384.8,-103.73C383.43,-95.43 381.99,-86.67 380.62,-78.28\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"384.05,-77.6 378.97,-68.3 377.14,-78.73 384.05,-77.6\"/>\n</g>\n<!-- 10 -->\n<g id=\"node11\" class=\"node\">\n<title>10</title>\n<polygon fill=\"#e5823a\" stroke=\"black\" points=\"612,-68 465,-68 465,0 612,0 612,-68\"/>\n<text text-anchor=\"middle\" x=\"538.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.011</text>\n<text text-anchor=\"middle\" x=\"538.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 15.8%</text>\n<text text-anchor=\"middle\" x=\"538.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.994, 0.006]</text>\n<text text-anchor=\"middle\" x=\"538.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = False</text>\n</g>\n<!-- 8&#45;&gt;10 -->\n<g id=\"edge10\" class=\"edge\">\n<title>8&#45;&gt;10</title>\n<path fill=\"none\" stroke=\"black\" d=\"M446.24,-103.73C459.09,-94.15 472.77,-83.96 485.55,-74.44\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"487.87,-77.08 493.8,-68.3 483.69,-71.47 487.87,-77.08\"/>\n</g>\n<!-- 14 -->\n<g id=\"node15\" class=\"node\">\n<title>14</title>\n<polygon fill=\"#40a0e6\" stroke=\"black\" points=\"974,-425 827,-425 827,-342 974,-342 974,-425\"/>\n<text text-anchor=\"middle\" x=\"900.5\" y=\"-409.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">spotlight &lt;= 0.5</text>\n<text text-anchor=\"middle\" x=\"900.5\" y=\"-394.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.062</text>\n<text text-anchor=\"middle\" x=\"900.5\" y=\"-379.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2.7%</text>\n<text text-anchor=\"middle\" x=\"900.5\" y=\"-364.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.032, 0.968]</text>\n<text text-anchor=\"middle\" x=\"900.5\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = True</text>\n</g>\n<!-- 13&#45;&gt;14 -->\n<g id=\"edge14\" class=\"edge\">\n<title>13&#45;&gt;14</title>\n<path fill=\"none\" stroke=\"black\" d=\"M900.5,-460.91C900.5,-452.65 900.5,-443.86 900.5,-435.3\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"904,-435.02 900.5,-425.02 897,-435.02 904,-435.02\"/>\n</g>\n<!-- 21 -->\n<g id=\"node22\" class=\"node\">\n<title>21</title>\n<polygon fill=\"#e5823b\" stroke=\"black\" points=\"1141,-425 994,-425 994,-342 1141,-342 1141,-425\"/>\n<text text-anchor=\"middle\" x=\"1067.5\" y=\"-409.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">country &lt;= 22.5</text>\n<text text-anchor=\"middle\" x=\"1067.5\" y=\"-394.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.019</text>\n<text text-anchor=\"middle\" x=\"1067.5\" y=\"-379.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 30.0%</text>\n<text text-anchor=\"middle\" x=\"1067.5\" y=\"-364.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.991, 0.009]</text>\n<text text-anchor=\"middle\" x=\"1067.5\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = False</text>\n</g>\n<!-- 13&#45;&gt;21 -->\n<g id=\"edge21\" class=\"edge\">\n<title>13&#45;&gt;21</title>\n<path fill=\"none\" stroke=\"black\" d=\"M958.44,-460.91C972.3,-451.2 987.2,-440.76 1001.4,-430.81\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1003.48,-433.63 1009.66,-425.02 999.46,-427.89 1003.48,-433.63\"/>\n</g>\n<!-- 15 -->\n<g id=\"node16\" class=\"node\">\n<title>15</title>\n<polygon fill=\"#3d9fe6\" stroke=\"black\" points=\"832,-306 677,-306 677,-223 832,-223 832,-306\"/>\n<text text-anchor=\"middle\" x=\"754.5\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">backers_count &lt;= 26.5</text>\n<text text-anchor=\"middle\" x=\"754.5\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.038</text>\n<text text-anchor=\"middle\" x=\"754.5\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2.7%</text>\n<text text-anchor=\"middle\" x=\"754.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.02, 0.98]</text>\n<text text-anchor=\"middle\" x=\"754.5\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = True</text>\n</g>\n<!-- 14&#45;&gt;15 -->\n<g id=\"edge15\" class=\"edge\">\n<title>14&#45;&gt;15</title>\n<path fill=\"none\" stroke=\"black\" d=\"M849.85,-341.91C837.96,-332.38 825.19,-322.15 812.99,-312.37\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"815.06,-309.54 805.06,-306.02 810.68,-315.01 815.06,-309.54\"/>\n</g>\n<!-- 20 -->\n<g id=\"node21\" class=\"node\">\n<title>20</title>\n<polygon fill=\"#e58139\" stroke=\"black\" points=\"967,-298.5 850,-298.5 850,-230.5 967,-230.5 967,-298.5\"/>\n<text text-anchor=\"middle\" x=\"908.5\" y=\"-283.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"middle\" x=\"908.5\" y=\"-268.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 0.0%</text>\n<text text-anchor=\"middle\" x=\"908.5\" y=\"-253.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1.0, 0.0]</text>\n<text text-anchor=\"middle\" x=\"908.5\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = False</text>\n</g>\n<!-- 14&#45;&gt;20 -->\n<g id=\"edge20\" class=\"edge\">\n<title>14&#45;&gt;20</title>\n<path fill=\"none\" stroke=\"black\" d=\"M903.28,-341.91C904.01,-331.2 904.8,-319.62 905.54,-308.78\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"909.04,-308.88 906.23,-298.67 902.06,-308.4 909.04,-308.88\"/>\n</g>\n<!-- 16 -->\n<g id=\"node17\" class=\"node\">\n<title>16</title>\n<polygon fill=\"#399de5\" stroke=\"black\" points=\"736,-179.5 619,-179.5 619,-111.5 736,-111.5 736,-179.5\"/>\n<text text-anchor=\"middle\" x=\"677.5\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"middle\" x=\"677.5\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1.5%</text>\n<text text-anchor=\"middle\" x=\"677.5\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.0, 1.0]</text>\n<text text-anchor=\"middle\" x=\"677.5\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = True</text>\n</g>\n<!-- 15&#45;&gt;16 -->\n<g id=\"edge16\" class=\"edge\">\n<title>15&#45;&gt;16</title>\n<path fill=\"none\" stroke=\"black\" d=\"M727.79,-222.91C720.38,-211.65 712.33,-199.42 704.88,-188.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"707.75,-186.1 699.33,-179.67 701.9,-189.94 707.75,-186.1\"/>\n</g>\n<!-- 17 -->\n<g id=\"node18\" class=\"node\">\n<title>17</title>\n<polygon fill=\"#42a1e6\" stroke=\"black\" points=\"901,-187 754,-187 754,-104 901,-104 901,-187\"/>\n<text text-anchor=\"middle\" x=\"827.5\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">pledged &lt;= 2630.5</text>\n<text text-anchor=\"middle\" x=\"827.5\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.083</text>\n<text text-anchor=\"middle\" x=\"827.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1.2%</text>\n<text text-anchor=\"middle\" x=\"827.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.043, 0.957]</text>\n<text text-anchor=\"middle\" x=\"827.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = True</text>\n</g>\n<!-- 15&#45;&gt;17 -->\n<g id=\"edge17\" class=\"edge\">\n<title>15&#45;&gt;17</title>\n<path fill=\"none\" stroke=\"black\" d=\"M779.83,-222.91C785.32,-214.1 791.19,-204.7 796.86,-195.61\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"799.89,-197.36 802.22,-187.02 793.95,-193.65 799.89,-197.36\"/>\n</g>\n<!-- 18 -->\n<g id=\"node19\" class=\"node\">\n<title>18</title>\n<polygon fill=\"#72b9ec\" stroke=\"black\" points=\"777,-68 630,-68 630,0 777,0 777,-68\"/>\n<text text-anchor=\"middle\" x=\"703.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.346</text>\n<text text-anchor=\"middle\" x=\"703.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 0.2%</text>\n<text text-anchor=\"middle\" x=\"703.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.222, 0.778]</text>\n<text text-anchor=\"middle\" x=\"703.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = True</text>\n</g>\n<!-- 17&#45;&gt;18 -->\n<g id=\"edge18\" class=\"edge\">\n<title>17&#45;&gt;18</title>\n<path fill=\"none\" stroke=\"black\" d=\"M781.33,-103.73C770.69,-94.33 759.38,-84.35 748.78,-74.99\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"751.02,-72.3 741.21,-68.3 746.39,-77.54 751.02,-72.3\"/>\n</g>\n<!-- 19 -->\n<g id=\"node20\" class=\"node\">\n<title>19</title>\n<polygon fill=\"#3c9fe5\" stroke=\"black\" points=\"942,-68 795,-68 795,0 942,0 942,-68\"/>\n<text text-anchor=\"middle\" x=\"868.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.033</text>\n<text text-anchor=\"middle\" x=\"868.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1.1%</text>\n<text text-anchor=\"middle\" x=\"868.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.017, 0.983]</text>\n<text text-anchor=\"middle\" x=\"868.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = True</text>\n</g>\n<!-- 17&#45;&gt;19 -->\n<g id=\"edge19\" class=\"edge\">\n<title>17&#45;&gt;19</title>\n<path fill=\"none\" stroke=\"black\" d=\"M842.77,-103.73C845.94,-95.24 849.3,-86.28 852.5,-77.73\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"855.8,-78.89 856.03,-68.3 849.25,-76.44 855.8,-78.89\"/>\n</g>\n<!-- 22 -->\n<g id=\"node23\" class=\"node\">\n<title>22</title>\n<polygon fill=\"#e5823b\" stroke=\"black\" points=\"1141,-306 994,-306 994,-223 1141,-223 1141,-306\"/>\n<text text-anchor=\"middle\" x=\"1067.5\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">spotlight &lt;= 0.5</text>\n<text text-anchor=\"middle\" x=\"1067.5\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.017</text>\n<text text-anchor=\"middle\" x=\"1067.5\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 30.0%</text>\n<text text-anchor=\"middle\" x=\"1067.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.991, 0.009]</text>\n<text text-anchor=\"middle\" x=\"1067.5\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = False</text>\n</g>\n<!-- 21&#45;&gt;22 -->\n<g id=\"edge22\" class=\"edge\">\n<title>21&#45;&gt;22</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1067.5,-341.91C1067.5,-333.65 1067.5,-324.86 1067.5,-316.3\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1071,-316.02 1067.5,-306.02 1064,-316.02 1071,-316.02\"/>\n</g>\n<!-- 27 -->\n<g id=\"node28\" class=\"node\">\n<title>27</title>\n<polygon fill=\"#ffffff\" stroke=\"black\" points=\"1409,-306 1254,-306 1254,-223 1409,-223 1409,-306\"/>\n<text text-anchor=\"middle\" x=\"1331.5\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">backers_count &lt;= 18.5</text>\n<text text-anchor=\"middle\" x=\"1331.5\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"middle\" x=\"1331.5\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 0.0%</text>\n<text text-anchor=\"middle\" x=\"1331.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.5, 0.5]</text>\n<text text-anchor=\"middle\" x=\"1331.5\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = False</text>\n</g>\n<!-- 21&#45;&gt;27 -->\n<g id=\"edge27\" class=\"edge\">\n<title>21&#45;&gt;27</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1141.04,-349.91C1173.11,-335.69 1210.96,-318.92 1244.43,-304.09\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1246.02,-307.21 1253.75,-299.96 1243.19,-300.81 1246.02,-307.21\"/>\n</g>\n<!-- 23 -->\n<g id=\"node24\" class=\"node\">\n<title>23</title>\n<polygon fill=\"#e5833d\" stroke=\"black\" points=\"1114,-187 953,-187 953,-104 1114,-104 1114,-187\"/>\n<text text-anchor=\"middle\" x=\"1033.5\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">category_name &lt;= 10.5</text>\n<text text-anchor=\"middle\" x=\"1033.5\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.035</text>\n<text text-anchor=\"middle\" x=\"1033.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 14.9%</text>\n<text text-anchor=\"middle\" x=\"1033.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.982, 0.018]</text>\n<text text-anchor=\"middle\" x=\"1033.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = False</text>\n</g>\n<!-- 22&#45;&gt;23 -->\n<g id=\"edge23\" class=\"edge\">\n<title>22&#45;&gt;23</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1055.7,-222.91C1053.25,-214.47 1050.64,-205.48 1048.1,-196.74\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1051.43,-195.65 1045.28,-187.02 1044.7,-197.6 1051.43,-195.65\"/>\n</g>\n<!-- 26 -->\n<g id=\"node27\" class=\"node\">\n<title>26</title>\n<polygon fill=\"#e58139\" stroke=\"black\" points=\"1254.5,-179.5 1132.5,-179.5 1132.5,-111.5 1254.5,-111.5 1254.5,-179.5\"/>\n<text text-anchor=\"middle\" x=\"1193.5\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"middle\" x=\"1193.5\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 15.1%</text>\n<text text-anchor=\"middle\" x=\"1193.5\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1.0, 0.0]</text>\n<text text-anchor=\"middle\" x=\"1193.5\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = False</text>\n</g>\n<!-- 22&#45;&gt;26 -->\n<g id=\"edge26\" class=\"edge\">\n<title>22&#45;&gt;26</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1111.22,-222.91C1123.81,-211.21 1137.55,-198.46 1150.12,-186.78\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1152.84,-189.04 1157.78,-179.67 1148.07,-183.91 1152.84,-189.04\"/>\n</g>\n<!-- 24 -->\n<g id=\"node25\" class=\"node\">\n<title>24</title>\n<polygon fill=\"#e5823a\" stroke=\"black\" points=\"1107,-68 960,-68 960,0 1107,0 1107,-68\"/>\n<text text-anchor=\"middle\" x=\"1033.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.014</text>\n<text text-anchor=\"middle\" x=\"1033.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 12.4%</text>\n<text text-anchor=\"middle\" x=\"1033.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.993, 0.007]</text>\n<text text-anchor=\"middle\" x=\"1033.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = False</text>\n</g>\n<!-- 23&#45;&gt;24 -->\n<g id=\"edge24\" class=\"edge\">\n<title>23&#45;&gt;24</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1033.5,-103.73C1033.5,-95.52 1033.5,-86.86 1033.5,-78.56\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1037,-78.3 1033.5,-68.3 1030,-78.3 1037,-78.3\"/>\n</g>\n<!-- 25 -->\n<g id=\"node26\" class=\"node\">\n<title>25</title>\n<polygon fill=\"#e78b48\" stroke=\"black\" points=\"1272,-68 1125,-68 1125,0 1272,0 1272,-68\"/>\n<text text-anchor=\"middle\" x=\"1198.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.133</text>\n<text text-anchor=\"middle\" x=\"1198.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2.5%</text>\n<text text-anchor=\"middle\" x=\"1198.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.929, 0.071]</text>\n<text text-anchor=\"middle\" x=\"1198.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = False</text>\n</g>\n<!-- 23&#45;&gt;25 -->\n<g id=\"edge25\" class=\"edge\">\n<title>23&#45;&gt;25</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1094.94,-103.73C1109.72,-93.92 1125.47,-83.46 1140.11,-73.75\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1142.19,-76.57 1148.59,-68.13 1138.32,-70.74 1142.19,-76.57\"/>\n</g>\n<!-- 28 -->\n<g id=\"node29\" class=\"node\">\n<title>28</title>\n<polygon fill=\"#e58139\" stroke=\"black\" points=\"1390,-179.5 1273,-179.5 1273,-111.5 1390,-111.5 1390,-179.5\"/>\n<text text-anchor=\"middle\" x=\"1331.5\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"middle\" x=\"1331.5\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 0.0%</text>\n<text text-anchor=\"middle\" x=\"1331.5\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1.0, 0.0]</text>\n<text text-anchor=\"middle\" x=\"1331.5\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = False</text>\n</g>\n<!-- 27&#45;&gt;28 -->\n<g id=\"edge28\" class=\"edge\">\n<title>27&#45;&gt;28</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1331.5,-222.91C1331.5,-212.2 1331.5,-200.62 1331.5,-189.78\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1335,-189.67 1331.5,-179.67 1328,-189.67 1335,-189.67\"/>\n</g>\n<!-- 29 -->\n<g id=\"node30\" class=\"node\">\n<title>29</title>\n<polygon fill=\"#399de5\" stroke=\"black\" points=\"1525,-179.5 1408,-179.5 1408,-111.5 1525,-111.5 1525,-179.5\"/>\n<text text-anchor=\"middle\" x=\"1466.5\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"middle\" x=\"1466.5\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 0.0%</text>\n<text text-anchor=\"middle\" x=\"1466.5\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.0, 1.0]</text>\n<text text-anchor=\"middle\" x=\"1466.5\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = True</text>\n</g>\n<!-- 27&#45;&gt;29 -->\n<g id=\"edge29\" class=\"edge\">\n<title>27&#45;&gt;29</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1378.34,-222.91C1391.96,-211.1 1406.83,-198.22 1420.4,-186.45\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1422.97,-188.86 1428.23,-179.67 1418.38,-183.57 1422.97,-188.86\"/>\n</g>\n<!-- 31 -->\n<g id=\"node32\" class=\"node\">\n<title>31</title>\n<polygon fill=\"#399de5\" stroke=\"black\" points=\"1120,-536.5 1003,-536.5 1003,-468.5 1120,-468.5 1120,-536.5\"/>\n<text text-anchor=\"middle\" x=\"1061.5\" y=\"-521.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"middle\" x=\"1061.5\" y=\"-506.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 0.5%</text>\n<text text-anchor=\"middle\" x=\"1061.5\" y=\"-491.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.0, 1.0]</text>\n<text text-anchor=\"middle\" x=\"1061.5\" y=\"-476.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = True</text>\n</g>\n<!-- 30&#45;&gt;31 -->\n<g id=\"edge31\" class=\"edge\">\n<title>30&#45;&gt;31</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1064.11,-579.91C1063.75,-569.2 1063.35,-557.62 1062.98,-546.78\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1066.47,-546.54 1062.63,-536.67 1059.48,-546.78 1066.47,-546.54\"/>\n</g>\n<!-- 32 -->\n<g id=\"node33\" class=\"node\">\n<title>32</title>\n<polygon fill=\"#e58139\" stroke=\"black\" points=\"1255,-536.5 1138,-536.5 1138,-468.5 1255,-468.5 1255,-536.5\"/>\n<text text-anchor=\"middle\" x=\"1196.5\" y=\"-521.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"middle\" x=\"1196.5\" y=\"-506.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 0.0%</text>\n<text text-anchor=\"middle\" x=\"1196.5\" y=\"-491.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1.0, 0.0]</text>\n<text text-anchor=\"middle\" x=\"1196.5\" y=\"-476.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = False</text>\n</g>\n<!-- 30&#45;&gt;32 -->\n<g id=\"edge32\" class=\"edge\">\n<title>30&#45;&gt;32</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1110.95,-579.91C1124.17,-568.1 1138.6,-555.22 1151.77,-543.45\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1154.24,-545.94 1159.36,-536.67 1149.57,-540.72 1154.24,-545.94\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(model, X_val_encoded, y_val):\n",
        "    if isinstance(model, XGBClassifier):\n",
        "        y_pred = model.predict(X_val_encoded, iteration_range=(0, model.best_iteration))\n",
        "    else:\n",
        "        y_pred = model.predict(X_val_encoded)\n",
        "    cm = confusion_matrix(y_val, y_pred)\n",
        "    disp = ConfusionMatrixDisplay(cm)\n",
        "    disp.plot(cmap='Blues')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Q5IMrvpNgKGH"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(pipe, X_val_drop, y_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "f8TI1xHGaiOp",
        "outputId": "e4aeb233-b5ec-4649-c9e9-733dfa21b9b9"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "oe = OrdinalEncoder()\n",
        "X_train_encoded = oe.fit_transform(X_train_drop)\n",
        "X_val_encoded = oe.transform(X_val_drop)\n",
        "X_train_sampled, y_train_sampled = SMOTE(random_state=2).fit_resample(X_train_encoded, y_train)"
      ],
      "metadata": {
        "id": "xSvppZbYQrIU"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DTC = DecisionTreeClassifier(max_depth=6, random_state=2)\n",
        "DTC.fit(X_train_sampled, y_train_sampled)\n",
        "plot_confusion_matrix(DTC, X_val_encoded, y_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "U_kd7k2RRKVZ",
        "outputId": "4175914b-8870-4ec2-b4d5-8ab792c23f23"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT8AAAEGCAYAAAAT05LOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAbZ0lEQVR4nO3debxWVd338c/3HAYlUWQUGZRuySErBx6xNG+SUrRB6y6TrNC8X9STZlm+fLQeMzV7rO47U9PKgVu0nLWgIue5VMQZR0hKQBQRHAH1cH7PH3uBR4Rz9j7nXFzD/r577RfXXntfe68L9dtae+29tiICM7Oyaap2BczMqsHhZ2al5PAzs1Jy+JlZKTn8zKyUelS7Am2px8ahXn2rXQ0r4EPbjax2FayAZ575Jy8uWaKuHKN5060iWlbk2jdWvHBdREzoyvkqpbbCr1dfem97ULWrYQXcfOcZ1a6CFbD3nmO7fIxoWZH7v9OVD549sMsnrJCaCj8zqwcC1f8VM4efmRUjoKm52rXoMoefmRWnLl02rAkOPzMryN1eMysrt/zMrHSEW35mVkZyy8/MSsqjvWZWPh7wMLMyEu72mllJNUDLr/5/gZltYKnbm2fp6EjSFEmLJc1uU/ZzSU9IeljSHyT1a7PteElzJT0pad825RNS2VxJx+X5FQ4/MytGQHNzvqVjFwJrz/pyA7BjRHwQeAo4HkDSDsDBwPvTd86R1CypGTgb2A/YAZiY9m2Xw8/MipPyLR2IiNuBpWuVXR8RLWn1bmB4+nwAcFlEvBER84C5wG5pmRsRT0fEm8Blad92OfzMrKBC3d6Bkma1WSYXPNnXgL+mz8OA+W22LUhl6ytvlwc8zKy4/KO9SyJiTOdOoR8ALcDvO/P9jjj8zKy4Co/2SjoU+BQwPt5+ufhCYESb3YanMtopXy93e82smLzX+zp5L6CkCcCxwGciYnmbTdOBgyX1ljQKGA3MBO4FRksaJakX2aDI9I7O45afmRXXTY+3SboUGEd2bXABcCLZ6G5v4AZlAXp3RHwjIh6VdAXwGFl3+IiIWJWOcyRwHdAMTImIRzs6t8PPzArqvsfbImLiOoovaGf/U4FT11E+A5hR5NwOPzMrzo+3mVnpeD4/Mysnz+piZmXl+fzMrJR8zc/MSkfu9ppZWbnlZ2ZlJIefmZVNNou9w8/MykZCTQ4/Mysht/zMrJQcfmZWSg4/MysfpaXOOfzMrBAht/zMrJyamvyEh5mVkFt+ZlY+vuZnZmXllp+ZlY4HPMystPx4m5mVj9ztNbOScviZWSk5/MysdBplwKP+b9M2sw1POZeODiNNkbRY0uw2Zf0l3SBpTvpz81QuSWdKmivpYUm7tPnOpLT/HEmT8vwEh5+ZFaPs8bY8Sw4XAhPWKjsOuCkiRgM3pXWA/YDRaZkM/BqysAROBMYCuwEnrg7M9jj8zKwwSbmWjkTE7cDStYoPAKamz1OBA9uUXxSZu4F+koYC+wI3RMTSiFgG3MC7A/VdfM3PzIrLf8lvoKRZbdbPjYhzO/jOkIhYlD4/BwxJn4cB89vstyCVra+8XQ6/TjjrhEPYd88dWbLsVT5y8E8AOPmoA9n3ozvy1lurmLdgCUec/DteeW0FPXs0c/r3J7Lz9iNpbW3luP++mr/dPweAK8/8JlsM2JTmHs3c/cA/OOZnl9PaGtX8aaX08qvLOea0y3ji6UVI4hffn8h5l9/GP55ZDMArr61g00025sapx1a5prWjwIDHkogY09nzRERIqsh/FBUNP0kTgDOAZuD8iDitkufbUC79892cd8Vt/Oakr64pu+WeJzjp7OmsWtXKj448gO8eug8/+tU0Jn12DwD2mPgTBm6+CVee8U32nvRzIoKvHT+FV19fCcDUn/4nB47fhWtuuK8qv6nMfvjLaxg3dnvOO/VrvPlWCytWvslvTzl0zfaTzvoDfd+zcdXqV2vydmm74HlJQyNiUerWLk7lC4ERbfYbnsoWAuPWKr+1o5NU7JqfpGbgbLKLlDsAEyXtUKnzbUh/f+AfLHtl+TvKbrnnCVatagXg3tnz2HJIPwC2HbUFd9z7JABLlr3Gy6+tYOftRwKsCb4ezU306tlM4FbfhvbKayu4+6F/8KVP7w5Ar5492KxvnzXbI4LpNz/IgZ/YZX2HKKXuuua3HtOB1SO2k4Bpbcq/mkZ9dwdeTt3j64B9JG2eBjr2SWXtquSAx27A3Ih4OiLeBC4ju2DZ8L78mQ9z498fA2D2nIVM2OsDNDc3MXLLAey03QiGDXl7IOqqM49gzvWn8drrbzDtpgeqVeXSeubZFxnQbxOOPvUSPnHoz/je/7uU5SveWLP9nof+waDN+/LeEYOrWMvaoyblWjo8jnQpcBewraQFkg4HTgM+IWkO8PG0DjADeBqYC5wHfBMgIpYCpwD3puXkVNauSnZ713URcuzaO0maTDZsDT03qWB1NozvHbYvLS2tXPHXewH43fS7eN/WQ7jlomOZv2gpMx+ex6rW1jX7f/6os+ndqwfnnnIoe43ZlltnPlGlmpfTqlWtPPLUAn589H+wy/u35oRfXs2vLr6RYyd/EoA/3nC/W33r0F3d3oiYuJ5N49exbwBHrOc4U4ApRc5d9VtdIuLciBgTEWPUo76vq0z81Fj22XNHJp9w4ZqyVata+cHp17DXIadxyDHnslnfjddcSF/tjTdbmHHbw+z/7x/YwDW2oYP7MXRQP3Z5/9YAfGrcTjzy1AIAWlpWMeO2h/jMeIffO6ji3d4NopLht76Lkw1p/Ie356ivfJwvfe+3rHjjrTXlG/fuSZ+NegEwbrftaGlp5cl5z/GejXsxZMCmADQ3N7HPnu9nzj+fr0rdy2zwgE3ZcnA/5v4r+7u/476nGL31FtnnWU+xzVZD2HJwv2pWseYIkPIttayS3d57gdGSRpGF3sHAlyp4vg3m/B8fyh67jmZAv02Y/edTOO3cGRx96D707tWDP5x9JACzHvkn3z3tMgb278vVZx1Ba2uw6IWX+MaJ2b2bfTbuzSW/+Dq9e/agqUncMWsOU665s5o/q7R+fPR/cORJF/NWSwsjtxzI6d/P/jWdduP9HPhxt/rerfZbdXko60ZX6ODS/sAvyW51mRIRp7a3f1OfwdF724MqVh/rfs/+7YxqV8EK2HvPsTxw/6wuJddGW7wvtpp0Vq59n/rZhPu6cp9fJVX0Pr+ImEE2QmNmjaIOurR5+AkPMytEQJOnsTezMnLLz8xKqREGPBx+ZlaMr/mZWRkJ5Z2otKY5/MysMLf8zKyUfM3PzMrH1/zMrIyyZ3vrP/0cfmZWWANkn8PPzIrzEx5mVj5yt9fMSmj1fH71zuFnZgU1xnx+Dj8zK6wBss/hZ2YFyQMeZlZCvs/PzErL4WdmpdQA2efwM7PiGqHlV/+TcpnZhpXznb158lHS0ZIelTRb0qWSNpI0StI9kuZKulxSr7Rv77Q+N23fuis/w+FnZoVkk5nmW9o9jjQMOAoYExE7kr3i9mDgp8DpEbENsAw4PH3lcGBZKj897ddpDj8zK6xJyrXk0APYWFIPoA+wCNgbuCptnwocmD4fkNZJ28erC/1vh5+ZFVag2ztQ0qw2y+TVx4iIhcB/Ac+Qhd7LwH3ASxHRknZbAAxLn4cB89N3W9L+Azr7GzzgYWaFqNjEBksiYsy6j6PNyVpzo4CXgCuBCd1SyRzc8jOzwpqUb+nAx4F5EfFCRLwFXAPsAfRL3WCA4cDC9HkhMAIgbd8MeLGzv2G9LT9JZwGxvu0RcVRnT2pm9a2bHm97BthdUh9gBTAemAXcAnweuAyYBExL+09P63el7TdHxHozqiPtdXtndfagZta4RDbi21URcY+kq4D7gRbgAeBc4C/AZZJ+nMouSF+5ALhY0lxgKdnIcKetN/wiYmrbdUl9ImJ5V05mZo2hu+Y1iIgTgRPXKn4a2G0d+64EvtA9Z85xzU/ShyU9BjyR1j8k6ZzuqoCZ1Rll8/nlWWpZngGPXwL7ki4sRsRDwF6VrJSZ1bbuesKjmnLd6hIR89dK8VWVqY6Z1TpB3huYa1qe8Jsv6SNASOoJfBt4vLLVMrNa1giTmebp9n4DOILs7upngZ3SupmVUN4ub603Djts+UXEEuCQDVAXM6sTjdDtzTPa+15Jf5L0gqTFkqZJeu+GqJyZ1SblXGpZnm7vJcAVwFBgS7Ln7y6tZKXMrLaV5VaXPhFxcUS0pOV3wEaVrpiZ1aZstLdbnu2tqvae7e2fPv5V0nFkz9kF8EVgxgaom5nVInU8UWk9aG/A4z6ysFv9K7/eZlsAx1eqUmZW22q9S5tHe8/2jtqQFTGz+rC621vvcj3hIWlHYAfaXOuLiIsqVSkzq20N3fJbTdKJwDiy8JsB7AfcCTj8zEqq/qMv32jv58kmGXwuIg4DPkQ2g6qZlZAEzU3KtdSyPN3eFRHRKqlF0qbAYtJU0mZWTqXo9gKzJPUDziMbAX6NbBppMyupBsi+XM/2fjN9/I2ka4FNI+LhylbLzGqVyP1O3prW3k3Ou7S3LSLur0yVzKym1cGMLXm01/L773a2Bdlb1bvVztuP5G/3/Kq7D2sV9MZbnte2jBr6ml9EfGxDVsTM6oOA5kYOPzOz9anxu1hycfiZWWEOPzMrnWyK+vpPvzwzOUvSlyX9MK2PlPSuFwqbWXl013x+kvpJukrSE5IeT+8J7y/pBklz0p+bp30l6UxJcyU93N4dKbl+Q459zgE+DExM668CZ3flpGZW37rxBUZnANdGxHZkj84+DhwH3BQRo4Gb0jpk8wqMTstk4Ndd+Q15wm9sRBwBrASIiGVAr66c1Mzql4AeUq6l3eNImwF7ARcARMSbEfEScAAwNe02FTgwfT4AuCgydwP9JA3t7O/IE35vSWomu7cPSYOA1s6e0MzqXze1/EYBLwD/I+kBSedLeg8wJCIWpX2eA4akz8OA+W2+vyCVdUqe8DsT+AMwWNKpZNNZ/aSzJzSz+iZlj7flWYCBkma1WSa3OVQPYBfg1xGxM/A6b3dxAYiIIDW8ulueZ3t/L+k+smmtBBwYEY9XojJmVh8KDPYuiYgx69m2AFgQEfek9avIwu95SUMjYlHq1i5O2xfyzhmlhqeyTskz2jsSWA78CZgOvJ7KzKykumO0NyKeA+ZL2jYVjQceI8uZSalsEjAtfZ4OfDWN+u4OvNyme1xYnvv8/sLbLzLaiKyf/iTw/s6e1Mzql6A7Jyr9FvB7Sb2Ap4HDyBplV0g6HPgXcFDadwawPzCXrEF2WFdOnKfb+4G26+nemm+uZ3cza3Td+E7eiHgQWFe3ePw69g3giO45cyee8IiI+yWN7a4KmFn9UQO8xSPPC4y+22a1iWx05tmK1cjMalqZXl3Zt83nFrJrgFdXpjpmVg8aPvzSzc19I+KYDVQfM6sDjTCxQXvT2PeIiBZJe2zICplZbcteXVntWnRdey2/mWTX9x6UNB24kuwObAAi4poK183MalRDv8CojY2AF8ne2bH6fr8AHH5mJVSGAY/BaaR3Nm+H3moVedbOzOpDAzT82g2/ZmATWOcNPQ4/s9ISTQ1+n9+iiDh5g9XEzOqCaPyWXwP8PDPrdoIeDXDRr73we9ezdWZmDd/yi4ilG7IiZlY/ynKri5nZOzRA9jn8zKwYke/9F7XO4WdmxcjdXjMroewJD4efmZVQ/Uefw8/MOqEBGn4OPzMrSo09n5+Z2bp4tNfMSssDHmZWPmrwaezNzNbF3V4zK61GaPk1QoCb2QamnEuuY0nNkh6Q9Oe0PkrSPZLmSrpcUq9U3jutz03bt+7Kb3D4mVkhApqlXEtO3wYeb7P+U+D0iNgGWAYcnsoPB5al8tPTfp3m8DOzwqR8S8fH0XDgk8D5aV1kL0u7Ku0yFTgwfT4grZO2j1cX+t8OPzMrSLn/BwyUNKvNMnmtg/0SOBZoTesDgJcioiWtLwCGpc/DgPkAafvLaf9O8YCHmRVWoL21JCLGrPsY+hSwOCLukzSum6qWm8PPzArJbnXpltHePYDPSNqf7P3gmwJnAP0k9Uitu+HAwrT/QmAEsEBSD2AzsneKd4q7vWZWTM7rfR21DiPi+IgYHhFbAwcDN0fEIcAtwOfTbpOAaenz9LRO2n5zRHT6NboOPzMrrEnKtXTS/wG+K2ku2TW9C1L5BcCAVP5d4Liu/AZ3e82skGwy0+49ZkTcCtyaPj8N7LaOfVYCX+iuczr8zKwwNcB0pg4/MyusAZ5uc/hV0jmX3MzFf/w7SOywzZac/cMvs1HvntWulq1lzOdOYpM+vWlubqK5uYnrpxzDslde5+snXMj8RUsZMbQ/555yGP027VPtqtaMRmj5VWzAQ9IUSYslza7UOWrZs4tf4reX38bNFx3LXZf/gNbWVq65/r5qV8vW4+pfHclNU4/l+inHAHDWxTfy0V3fx11XnMBHd30fZ118Y5VrWDtWX/PLs9SySo72XghMqODxa15LyypWvvEWLS2rWL7yTbYYtFm1q2Q5XXfHbA7aP7vmftD+u3HtHY9UuUY1JOdIb61PeFqxbm9E3N7VWRfq2ZaD+/GtL4/nA58+gY169+JjY7dj7923r3a1bB0kOPg7v0aCrxywB1858CO8sPRVhgzM/s9q8IBNeWHpq1WuZW2p7VjLp+rX/NKzfpMBRowcWeXadJ+XXlnOjNsf4cFpJ7FZ3z4cetwFXD5jJl/c/10j+FZl03/zbYYO6scLS1/li985h222GvyO7ZIa4gJ/d2mU9/ZW/SbniDg3IsZExJhBAwdVuzrd5taZT7DVlgMYuHlfevZo5tMf+xAzH55X7WrZOgwd1A+AQf37st9eH+SBx59hUP++PL/kZQCeX/IyAzfvW80q1pzunM+vWqoefo1q+Bb9mfXIPJavfJOI4LZ7n2TbUUOqXS1by+sr3uC111eu+XzbzCfY7r1D2WfPHblixkwArpgxk30/umM1q1l7GiD9qt7tbVRjdtyaz4zfmXFf/inNzU18cNvhTPrsHtWulq1lydJXOez47OmpllWtfO4Tu7L37tuz0/Yjmfx//4dL/nw3w7foz7k/PrS6Fa0xjdDtVReeC27/wNKlwDhgIPA8cGJEXNDed3bddUz87Z5ZFamPVcYbb62qdhWsgHF7jOWB+2d1Kbm2/8DOcdG0W3Ptu9u/9btvfVNaVVslR3snVurYZlZl9d/wc7fXzIrJLufVf/o5/MysmJzv56h1Dj8zK6wBss/hZ2ZFqSFeWu7wM7PCGiD7HH5mVkwd3L+ci8PPzIprgPRz+JlZYb7VxcxKydf8zKx8fJ+fmZWVu71mVjrCLT8zK6kGyD5PZmpmndANk5lKGiHpFkmPSXpU0rdTeX9JN0iak/7cPJVL0pmS5kp6WNIuXfkJDj8zK6yb3t7WAnwvInYAdgeOkLQDcBxwU0SMBm5K6wD7AaPTMhn4dZd+Q1e+bGbl1B2z2EfEooi4P31+FXgcGAYcAExNu00FDkyfDwAuiszdQD9JQzv7Gxx+ZlZc/vQbKGlWm2XyOg+XveZ2Z+AeYEhELEqbngNWv/xmGDC/zdcWpLJO8YCHmRVScDLTJR1NYy9pE+Bq4DsR8UrbGWMiIiRV5F0bbvmZWTHpJuc8S4eHknqSBd/vI+KaVPz86u5s+nNxKl8IjGjz9eGprFMcfmZWWHdc81PWxLsAeDwiftFm03RgUvo8CZjWpvyradR3d+DlNt3jwtztNbOCum0y0z2ArwCPSHowlX0fOA24QtLhwL+Ag9K2GcD+wFxgOXBYV07u8DOzwroj+yLiTtbfQBy/jv0DOKLrZ844/MysEE9mambl1QDp5/Azs8I8q4uZlZJndTGz8hE0OfzMrJzqP/0cfmZWiCczNbPSaoDsc/iZWXFu+ZlZKXXT421V5fAzs8LqP/ocfmZWUN7pqmqdw8/MCvMTHmZWTvWffQ4/MyuuAbLP4WdmReV6LWXNc/iZWSGN8oSH3+FhZqXklp+ZFdYILT+Hn5kV5ltdzKx8fJOzmZVRowx4OPzMrDB3e82slNzyM7NSaoDsc/iZWSc0QPo5/MysEEFDPN6miKh2HdaQ9ALwr2rXowIGAkuqXQkrpFH/mW0VEYO6cgBJ15L9/eSxJCImdOV8lVJT4deoJM2KiDHVrofl539mjc/P9ppZKTn8zKyUHH4bxrnVroAV5n9mDc7X/MyslNzyM7NScviZWSk5/CpI0gRJT0qaK+m4atfHOiZpiqTFkmZXuy5WWQ6/CpHUDJwN7AfsAEyUtEN1a2U5XAjU5E251r0cfpWzGzA3Ip6OiDeBy4ADqlwn60BE3A4srXY9rPIcfpUzDJjfZn1BKjOzGuDwM7NScvhVzkJgRJv14anMzGqAw69y7gVGSxolqRdwMDC9ynUys8ThVyER0QIcCVwHPA5cERGPVrdW1hFJlwJ3AdtKWiDp8GrXySrDj7eZWSm55WdmpeTwM7NScviZWSk5/MyslBx+ZlZKDr86ImmVpAclzZZ0paQ+XTjWhZI+nz6f396kC5LGSfpIJ87xT0nvesvX+srX2ue1guf6kaRjitbRysvhV19WRMROEbEj8CbwjbYbJXXqPcwR8Z8R8Vg7u4wDCoefWS1z+NWvO4BtUqvsDknTgcckNUv6uaR7JT0s6esAyvwqzS94IzB49YEk3SppTPo8QdL9kh6SdJOkrclC9ujU6vyopEGSrk7nuFfSHum7AyRdL+lRSeeTvd+6XZL+KOm+9J3Ja207PZXfJGlQKvs3Sdem79whabvu+Mu08ulUS8GqK7Xw9gOuTUW7ADtGxLwUIC9HxP+S1Bv4m6TrgZ2BbcnmFhwCPAZMWeu4g4DzgL3SsfpHxFJJvwFei4j/SvtdApweEXdKGkn2FMv2wInAnRFxsqRPAnmejvhaOsfGwL2Sro6IF4H3ALMi4mhJP0zHPpLsxULfiIg5ksYC5wB7d+Kv0UrO4VdfNpb0YPp8B3ABWXd0ZkTMS+X7AB9cfT0P2AwYDewFXBoRq4BnJd28juPvDty++lgRsb557T4O7CCtadhtKmmTdI7Ppe/+RdKyHL/pKEmfTZ9HpLq+CLQCl6fy3wHXpHN8BLiyzbl75ziH2bs4/OrLiojYqW1BCoHX2xYB34qI69bab/9urEcTsHtErFxHXXKTNI4sSD8cEcsl3QpstJ7dI533pbX/Dsw6w9f8Gs91wP+W1BNA0vskvQe4HfhiuiY4FPjYOr57N7CXpFHpu/1T+atA3zb7XQ98a/WKpNVhdDvwpVS2H7B5B3XdDFiWgm87spbnak3A6tbrl8i6068A8yR9IZ1Dkj7UwTnM1snh13jOJ7ued396Cc9vyVr4fwDmpG0Xkc1c8g4R8QIwmayL+RBvdzv/BHx29YAHcBQwJg2oPMbbo84nkYXno2Td32c6qOu1QA9JjwOnkYXvaq8Du6XfsDdwcio/BDg81e9R/GoA6yTP6mJmpeSWn5mVksPPzErJ4WdmpeTwM7NScviZWSk5/MyslBx+ZlZK/x/Ed+2kT61B7wAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"검증 정확도\", DTC.score(X_val_encoded, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57xO7U0PYrBI",
        "outputId": "bb97af13-84a5-4c8c-da63-ae059c39059f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "검증 정확도 0.9471086036671368\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 해석"
      ],
      "metadata": {
        "id": "JVLKplakrJxc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "permuter = PermutationImportance(\n",
        "    DTC,  # model\n",
        "    scoring=\"roc_auc\",  # metric\n",
        "    n_iter=10,  # 다른 random seed를 사용하여 10번 반복\n",
        "    random_state=2,\n",
        ")\n",
        "\n",
        "permuter.fit(X_val_encoded, y_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITsSPG6orIVs",
        "outputId": "3a455383-b045-442a-cbb1-b804e319c0f2"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PermutationImportance(estimator=DecisionTreeClassifier(max_depth=6,\n",
              "                                                       random_state=2),\n",
              "                      n_iter=10, random_state=2, scoring='roc_auc')"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_names = X_val_encoded.columns.tolist()\n",
        "pi = pd.Series(permuter.feature_importances_, feature_names).sort_values()\n",
        "pi.plot.barh()\n",
        "plt.title(\"Permutation Importance\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "-aqerQsitFme",
        "outputId": "c6bfa98d-055d-4458-a99e-2f01276b2136"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Permutation Importance')"
            ]
          },
          "metadata": {},
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eli5.show_weights(\n",
        "    permuter,\n",
        "    top=None,\n",
        "    feature_names=feature_names,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "JQIEnEM50QmH",
        "outputId": "6e3b1c28-d81d-4999-8148-27c7a79561cd"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
              "    <thead>\n",
              "    <tr style=\"border: none;\">\n",
              "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
              "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "    </tr>\n",
              "    </thead>\n",
              "    <tbody>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.3501\n",
              "                \n",
              "                    &plusmn; 0.0742\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                spotlight\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 85.79%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.2149\n",
              "                \n",
              "                    &plusmn; 0.0417\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                category_parent\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.30%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0103\n",
              "                \n",
              "                    &plusmn; 0.0134\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                goal\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.60%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0078\n",
              "                \n",
              "                    &plusmn; 0.0031\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                converted_pledged_amount\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.26%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0031\n",
              "                \n",
              "                    &plusmn; 0.0025\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                category_name\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.80%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0005\n",
              "                \n",
              "                    &plusmn; 0.0178\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                usd_pledged\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                staff_pick\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                pledged\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                currency\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 99.20%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0036\n",
              "                \n",
              "                    &plusmn; 0.0081\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                country\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 99.07%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0044\n",
              "                \n",
              "                    &plusmn; 0.0110\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                backers_count\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "    \n",
              "    </tbody>\n",
              "</table>\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "찐 모델 생성"
      ],
      "metadata": {
        "id": "qC73ainT5Krh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_encoded = X_train_encoded.drop([\"spotlight\"], axis=1)\n",
        "X_test = X_val_encoded.drop([\"spotlight\"], axis=1)\n",
        "X_train_sampled, y_train_sampled = SMOTE(random_state=2).fit_resample(X_train_encoded, y_train)"
      ],
      "metadata": {
        "id": "3BJefBucBWYE"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    \"randomforestclassifier__max_depth\": [2, 4, 6, 8, 10, 15, 20, 25, 30],\n",
        "    \"randomforestclassifier__max_features\": [2, 4, 6, 8, 10, 15, 20, 25, 30],\n",
        "    \"randomforestclassifier__min_samples_leaf\": [2, 4, 6, 8, 10, 15, 20, 25, 30],\n",
        "    \"randomforestclassifier__bootstrap\": [\"True\", \"False\"],\n",
        "    \"randomforestclassifier__class_weight\": ['None', 'balanced', 'balanced_subsample'],\n",
        "    \"randomforestclassifier__criterion\": ['gini', 'entropy', 'log_loss'],\n",
        "    \"randomforestclassifier__n_estimators\": [180, 190, 200, 210, 220],\n",
        "    \"randomforestclassifier__warm_start\": [\"True\", \"False\"]\n",
        "}\n"
      ],
      "metadata": {
        "id": "nMhe4vPP4n0j"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_pipe = make_pipeline(\n",
        "    RandomForestClassifier(random_state=2, oob_score=True, n_jobs=-1)\n",
        ")"
      ],
      "metadata": {
        "id": "PZfg0GPd4vck"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "randomized_search = RandomizedSearchCV(\n",
        "    param_pipe,\n",
        "    param_distributions=params,\n",
        "    scoring=\"roc_auc\",\n",
        "    n_iter=30,\n",
        "    cv=3,\n",
        "    verbose=3,\n",
        "    random_state=2,\n",
        ")\n",
        "randomized_search.fit(X_train_sampled, y_train_sampled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHUQ5TAo6AOp",
        "outputId": "01eeda91-f4f8-4c02-f4c9-07e7502465e9"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:765: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3] END randomforestclassifier__bootstrap=False, randomforestclassifier__class_weight=balanced, randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=6, randomforestclassifier__max_features=4, randomforestclassifier__min_samples_leaf=20, randomforestclassifier__n_estimators=210, randomforestclassifier__warm_start=True;, score=0.979 total time=   4.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:765: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/3] END randomforestclassifier__bootstrap=False, randomforestclassifier__class_weight=balanced, randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=6, randomforestclassifier__max_features=4, randomforestclassifier__min_samples_leaf=20, randomforestclassifier__n_estimators=210, randomforestclassifier__warm_start=True;, score=0.987 total time=   4.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:765: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3] END randomforestclassifier__bootstrap=False, randomforestclassifier__class_weight=balanced, randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=6, randomforestclassifier__max_features=4, randomforestclassifier__min_samples_leaf=20, randomforestclassifier__n_estimators=210, randomforestclassifier__warm_start=True;, score=0.985 total time=   3.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:765: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3] END randomforestclassifier__bootstrap=False, randomforestclassifier__class_weight=balanced, randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=25, randomforestclassifier__max_features=10, randomforestclassifier__min_samples_leaf=25, randomforestclassifier__n_estimators=220, randomforestclassifier__warm_start=False;, score=0.983 total time=   8.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:765: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/3] END randomforestclassifier__bootstrap=False, randomforestclassifier__class_weight=balanced, randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=25, randomforestclassifier__max_features=10, randomforestclassifier__min_samples_leaf=25, randomforestclassifier__n_estimators=220, randomforestclassifier__warm_start=False;, score=0.993 total time=   9.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:765: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3] END randomforestclassifier__bootstrap=False, randomforestclassifier__class_weight=balanced, randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=25, randomforestclassifier__max_features=10, randomforestclassifier__min_samples_leaf=25, randomforestclassifier__n_estimators=220, randomforestclassifier__warm_start=False;, score=0.992 total time=  13.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:765: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3] END randomforestclassifier__bootstrap=False, randomforestclassifier__class_weight=balanced, randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=6, randomforestclassifier__min_samples_leaf=15, randomforestclassifier__n_estimators=210, randomforestclassifier__warm_start=True;, score=0.960 total time=   3.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:765: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/3] END randomforestclassifier__bootstrap=False, randomforestclassifier__class_weight=balanced, randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=6, randomforestclassifier__min_samples_leaf=15, randomforestclassifier__n_estimators=210, randomforestclassifier__warm_start=True;, score=0.962 total time=   2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:765: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3] END randomforestclassifier__bootstrap=False, randomforestclassifier__class_weight=balanced, randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=6, randomforestclassifier__min_samples_leaf=15, randomforestclassifier__n_estimators=210, randomforestclassifier__warm_start=True;, score=0.966 total time=   2.0s\n",
            "[CV 1/3] END randomforestclassifier__bootstrap=False, randomforestclassifier__class_weight=None, randomforestclassifier__criterion=log_loss, randomforestclassifier__max_depth=15, randomforestclassifier__max_features=6, randomforestclassifier__min_samples_leaf=4, randomforestclassifier__n_estimators=200, randomforestclassifier__warm_start=True;, score=nan total time=   0.0s\n",
            "[CV 2/3] END randomforestclassifier__bootstrap=False, randomforestclassifier__class_weight=None, randomforestclassifier__criterion=log_loss, randomforestclassifier__max_depth=15, randomforestclassifier__max_features=6, randomforestclassifier__min_samples_leaf=4, randomforestclassifier__n_estimators=200, randomforestclassifier__warm_start=True;, score=nan total time=   0.0s\n",
            "[CV 3/3] END randomforestclassifier__bootstrap=False, randomforestclassifier__class_weight=None, randomforestclassifier__criterion=log_loss, randomforestclassifier__max_depth=15, randomforestclassifier__max_features=6, randomforestclassifier__min_samples_leaf=4, randomforestclassifier__n_estimators=200, randomforestclassifier__warm_start=True;, score=nan total time=   0.0s\n",
            "[CV 1/3] END randomforestclassifier__bootstrap=True, randomforestclassifier__class_weight=balanced, randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=15, randomforestclassifier__max_features=25, randomforestclassifier__min_samples_leaf=6, randomforestclassifier__n_estimators=210, randomforestclassifier__warm_start=False;, score=nan total time=   0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:765: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
            "  warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:765: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/3] END randomforestclassifier__bootstrap=True, randomforestclassifier__class_weight=balanced, randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=15, randomforestclassifier__max_features=25, randomforestclassifier__min_samples_leaf=6, randomforestclassifier__n_estimators=210, randomforestclassifier__warm_start=False;, score=nan total time=   1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:765: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3] END randomforestclassifier__bootstrap=True, randomforestclassifier__class_weight=balanced, randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=15, randomforestclassifier__max_features=25, randomforestclassifier__min_samples_leaf=6, randomforestclassifier__n_estimators=210, randomforestclassifier__warm_start=False;, score=nan total time=   1.5s\n",
            "[CV 1/3] END randomforestclassifier__bootstrap=False, randomforestclassifier__class_weight=None, randomforestclassifier__criterion=log_loss, randomforestclassifier__max_depth=2, randomforestclassifier__max_features=2, randomforestclassifier__min_samples_leaf=10, randomforestclassifier__n_estimators=190, randomforestclassifier__warm_start=True;, score=nan total time=   0.0s\n",
            "[CV 2/3] END randomforestclassifier__bootstrap=False, randomforestclassifier__class_weight=None, randomforestclassifier__criterion=log_loss, randomforestclassifier__max_depth=2, randomforestclassifier__max_features=2, randomforestclassifier__min_samples_leaf=10, randomforestclassifier__n_estimators=190, randomforestclassifier__warm_start=True;, score=nan total time=   0.0s\n",
            "[CV 3/3] END randomforestclassifier__bootstrap=False, randomforestclassifier__class_weight=None, randomforestclassifier__criterion=log_loss, randomforestclassifier__max_depth=2, randomforestclassifier__max_features=2, randomforestclassifier__min_samples_leaf=10, randomforestclassifier__n_estimators=190, randomforestclassifier__warm_start=True;, score=nan total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:765: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3] END randomforestclassifier__bootstrap=True, randomforestclassifier__class_weight=balanced_subsample, randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=8, randomforestclassifier__max_features=15, randomforestclassifier__min_samples_leaf=4, randomforestclassifier__n_estimators=190, randomforestclassifier__warm_start=True;, score=nan total time=   1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:765: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/3] END randomforestclassifier__bootstrap=True, randomforestclassifier__class_weight=balanced_subsample, randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=8, randomforestclassifier__max_features=15, randomforestclassifier__min_samples_leaf=4, randomforestclassifier__n_estimators=190, randomforestclassifier__warm_start=True;, score=nan total time=   1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:765: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3] END randomforestclassifier__bootstrap=True, randomforestclassifier__class_weight=balanced_subsample, randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=8, randomforestclassifier__max_features=15, randomforestclassifier__min_samples_leaf=4, randomforestclassifier__n_estimators=190, randomforestclassifier__warm_start=True;, score=nan total time=   1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:765: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3] END randomforestclassifier__bootstrap=True, randomforestclassifier__class_weight=balanced, randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=30, randomforestclassifier__min_samples_leaf=30, randomforestclassifier__n_estimators=180, randomforestclassifier__warm_start=False;, score=nan total time=   1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:765: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/3] END randomforestclassifier__bootstrap=True, randomforestclassifier__class_weight=balanced, randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=30, randomforestclassifier__min_samples_leaf=30, randomforestclassifier__n_estimators=180, randomforestclassifier__warm_start=False;, score=nan total time=   1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:765: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3] END randomforestclassifier__bootstrap=True, randomforestclassifier__class_weight=balanced, randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=30, randomforestclassifier__min_samples_leaf=30, randomforestclassifier__n_estimators=180, randomforestclassifier__warm_start=False;, score=nan total time=   1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:765: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3] END randomforestclassifier__bootstrap=True, randomforestclassifier__class_weight=balanced, randomforestclassifier__criterion=log_loss, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=25, randomforestclassifier__min_samples_leaf=8, randomforestclassifier__n_estimators=200, randomforestclassifier__warm_start=False;, score=nan total time=   1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:765: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/3] END randomforestclassifier__bootstrap=True, randomforestclassifier__class_weight=balanced, randomforestclassifier__criterion=log_loss, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=25, randomforestclassifier__min_samples_leaf=8, randomforestclassifier__n_estimators=200, randomforestclassifier__warm_start=False;, score=nan total time=   1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:765: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3] END randomforestclassifier__bootstrap=True, randomforestclassifier__class_weight=balanced, randomforestclassifier__criterion=log_loss, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=25, randomforestclassifier__min_samples_leaf=8, randomforestclassifier__n_estimators=200, randomforestclassifier__warm_start=False;, score=nan total time=   1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:765: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3] END randomforestclassifier__bootstrap=True, randomforestclassifier__class_weight=balanced, randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=25, randomforestclassifier__max_features=25, randomforestclassifier__min_samples_leaf=30, randomforestclassifier__n_estimators=180, randomforestclassifier__warm_start=False;, score=nan total time=   1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:765: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/3] END randomforestclassifier__bootstrap=True, randomforestclassifier__class_weight=balanced, randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=25, randomforestclassifier__max_features=25, randomforestclassifier__min_samples_leaf=30, randomforestclassifier__n_estimators=180, randomforestclassifier__warm_start=False;, score=nan total time=   1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:765: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3] END randomforestclassifier__bootstrap=True, randomforestclassifier__class_weight=balanced, randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=25, randomforestclassifier__max_features=25, randomforestclassifier__min_samples_leaf=30, randomforestclassifier__n_estimators=180, randomforestclassifier__warm_start=False;, score=nan total time=   1.0s\n",
            "[CV 1/3] END randomforestclassifier__bootstrap=False, randomforestclassifier__class_weight=None, randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=20, randomforestclassifier__max_features=6, randomforestclassifier__min_samples_leaf=15, randomforestclassifier__n_estimators=190, randomforestclassifier__warm_start=False;, score=nan total time=   0.0s\n",
            "[CV 2/3] END randomforestclassifier__bootstrap=False, randomforestclassifier__class_weight=None, randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=20, randomforestclassifier__max_features=6, randomforestclassifier__min_samples_leaf=15, randomforestclassifier__n_estimators=190, randomforestclassifier__warm_start=False;, score=nan total time=   0.0s\n",
            "[CV 3/3] END randomforestclassifier__bootstrap=False, randomforestclassifier__class_weight=None, randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=20, randomforestclassifier__max_features=6, randomforestclassifier__min_samples_leaf=15, randomforestclassifier__n_estimators=190, randomforestclassifier__warm_start=False;, score=nan total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:765: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3] END randomforestclassifier__bootstrap=True, randomforestclassifier__class_weight=balanced, randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=8, randomforestclassifier__max_features=10, randomforestclassifier__min_samples_leaf=30, randomforestclassifier__n_estimators=180, randomforestclassifier__warm_start=False;, score=0.976 total time=   6.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:765: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/3] END randomforestclassifier__bootstrap=True, randomforestclassifier__class_weight=balanced, randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=8, randomforestclassifier__max_features=10, randomforestclassifier__min_samples_leaf=30, randomforestclassifier__n_estimators=180, randomforestclassifier__warm_start=False;, score=0.986 total time=   3.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:765: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3] END randomforestclassifier__bootstrap=True, randomforestclassifier__class_weight=balanced, randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=8, randomforestclassifier__max_features=10, randomforestclassifier__min_samples_leaf=30, randomforestclassifier__n_estimators=180, randomforestclassifier__warm_start=False;, score=0.985 total time=   3.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:765: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3] END randomforestclassifier__bootstrap=False, randomforestclassifier__class_weight=balanced_subsample, randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=20, randomforestclassifier__max_features=4, randomforestclassifier__min_samples_leaf=10, randomforestclassifier__n_estimators=210, randomforestclassifier__warm_start=False;, score=0.992 total time=   4.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:765: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/3] END randomforestclassifier__bootstrap=False, randomforestclassifier__class_weight=balanced_subsample, randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=20, randomforestclassifier__max_features=4, randomforestclassifier__min_samples_leaf=10, randomforestclassifier__n_estimators=210, randomforestclassifier__warm_start=False;, score=0.997 total time=   5.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:765: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3] END randomforestclassifier__bootstrap=False, randomforestclassifier__class_weight=balanced_subsample, randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=20, randomforestclassifier__max_features=4, randomforestclassifier__min_samples_leaf=10, randomforestclassifier__n_estimators=210, randomforestclassifier__warm_start=False;, score=0.998 total time=   3.3s\n",
            "[CV 1/3] END randomforestclassifier__bootstrap=False, randomforestclassifier__class_weight=balanced_subsample, randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=6, randomforestclassifier__max_features=30, randomforestclassifier__min_samples_leaf=6, randomforestclassifier__n_estimators=220, randomforestclassifier__warm_start=True;, score=nan total time=   0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:765: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
            "  warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:765: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/3] END randomforestclassifier__bootstrap=False, randomforestclassifier__class_weight=balanced_subsample, randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=6, randomforestclassifier__max_features=30, randomforestclassifier__min_samples_leaf=6, randomforestclassifier__n_estimators=220, randomforestclassifier__warm_start=True;, score=nan total time=   1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:765: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3] END randomforestclassifier__bootstrap=False, randomforestclassifier__class_weight=balanced_subsample, randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=6, randomforestclassifier__max_features=30, randomforestclassifier__min_samples_leaf=6, randomforestclassifier__n_estimators=220, randomforestclassifier__warm_start=True;, score=nan total time=   1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:765: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3] END randomforestclassifier__bootstrap=False, randomforestclassifier__class_weight=balanced_subsample, randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=20, randomforestclassifier__max_features=4, randomforestclassifier__min_samples_leaf=4, randomforestclassifier__n_estimators=200, randomforestclassifier__warm_start=True;, score=0.995 total time=   3.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:765: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/3] END randomforestclassifier__bootstrap=False, randomforestclassifier__class_weight=balanced_subsample, randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=20, randomforestclassifier__max_features=4, randomforestclassifier__min_samples_leaf=4, randomforestclassifier__n_estimators=200, randomforestclassifier__warm_start=True;, score=0.998 total time=   2.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:765: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3] END randomforestclassifier__bootstrap=False, randomforestclassifier__class_weight=balanced_subsample, randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=20, randomforestclassifier__max_features=4, randomforestclassifier__min_samples_leaf=4, randomforestclassifier__n_estimators=200, randomforestclassifier__warm_start=True;, score=0.999 total time=   4.8s\n",
            "[CV 1/3] END randomforestclassifier__bootstrap=True, randomforestclassifier__class_weight=None, randomforestclassifier__criterion=log_loss, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=8, randomforestclassifier__min_samples_leaf=30, randomforestclassifier__n_estimators=220, randomforestclassifier__warm_start=True;, score=nan total time=   0.0s\n",
            "[CV 2/3] END randomforestclassifier__bootstrap=True, randomforestclassifier__class_weight=None, randomforestclassifier__criterion=log_loss, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=8, randomforestclassifier__min_samples_leaf=30, randomforestclassifier__n_estimators=220, randomforestclassifier__warm_start=True;, score=nan total time=   0.0s\n",
            "[CV 3/3] END randomforestclassifier__bootstrap=True, randomforestclassifier__class_weight=None, randomforestclassifier__criterion=log_loss, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=8, randomforestclassifier__min_samples_leaf=30, randomforestclassifier__n_estimators=220, randomforestclassifier__warm_start=True;, score=nan total time=   0.0s\n",
            "[CV 1/3] END randomforestclassifier__bootstrap=False, randomforestclassifier__class_weight=balanced_subsample, randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=6, randomforestclassifier__max_features=20, randomforestclassifier__min_samples_leaf=8, randomforestclassifier__n_estimators=200, randomforestclassifier__warm_start=False;, score=nan total time=   0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:765: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
            "  warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:765: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/3] END randomforestclassifier__bootstrap=False, randomforestclassifier__class_weight=balanced_subsample, randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=6, randomforestclassifier__max_features=20, randomforestclassifier__min_samples_leaf=8, randomforestclassifier__n_estimators=200, randomforestclassifier__warm_start=False;, score=nan total time=   1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:765: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3] END randomforestclassifier__bootstrap=False, randomforestclassifier__class_weight=balanced_subsample, randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=6, randomforestclassifier__max_features=20, randomforestclassifier__min_samples_leaf=8, randomforestclassifier__n_estimators=200, randomforestclassifier__warm_start=False;, score=nan total time=   1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:765: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3] END randomforestclassifier__bootstrap=True, randomforestclassifier__class_weight=balanced_subsample, randomforestclassifier__criterion=log_loss, randomforestclassifier__max_depth=8, randomforestclassifier__max_features=6, randomforestclassifier__min_samples_leaf=8, randomforestclassifier__n_estimators=210, randomforestclassifier__warm_start=True;, score=nan total time=   1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:765: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/3] END randomforestclassifier__bootstrap=True, randomforestclassifier__class_weight=balanced_subsample, randomforestclassifier__criterion=log_loss, randomforestclassifier__max_depth=8, randomforestclassifier__max_features=6, randomforestclassifier__min_samples_leaf=8, randomforestclassifier__n_estimators=210, randomforestclassifier__warm_start=True;, score=nan total time=   1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:765: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3] END randomforestclassifier__bootstrap=True, randomforestclassifier__class_weight=balanced_subsample, randomforestclassifier__criterion=log_loss, randomforestclassifier__max_depth=8, randomforestclassifier__max_features=6, randomforestclassifier__min_samples_leaf=8, randomforestclassifier__n_estimators=210, randomforestclassifier__warm_start=True;, score=nan total time=   1.0s\n",
            "[CV 1/3] END randomforestclassifier__bootstrap=True, randomforestclassifier__class_weight=None, randomforestclassifier__criterion=log_loss, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=15, randomforestclassifier__min_samples_leaf=20, randomforestclassifier__n_estimators=200, randomforestclassifier__warm_start=False;, score=nan total time=   0.0s\n",
            "[CV 2/3] END randomforestclassifier__bootstrap=True, randomforestclassifier__class_weight=None, randomforestclassifier__criterion=log_loss, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=15, randomforestclassifier__min_samples_leaf=20, randomforestclassifier__n_estimators=200, randomforestclassifier__warm_start=False;, score=nan total time=   0.0s\n",
            "[CV 3/3] END randomforestclassifier__bootstrap=True, randomforestclassifier__class_weight=None, randomforestclassifier__criterion=log_loss, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=15, randomforestclassifier__min_samples_leaf=20, randomforestclassifier__n_estimators=200, randomforestclassifier__warm_start=False;, score=nan total time=   0.0s\n",
            "[CV 1/3] END randomforestclassifier__bootstrap=False, randomforestclassifier__class_weight=None, randomforestclassifier__criterion=log_loss, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=6, randomforestclassifier__min_samples_leaf=15, randomforestclassifier__n_estimators=220, randomforestclassifier__warm_start=True;, score=nan total time=   0.0s\n",
            "[CV 2/3] END randomforestclassifier__bootstrap=False, randomforestclassifier__class_weight=None, randomforestclassifier__criterion=log_loss, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=6, randomforestclassifier__min_samples_leaf=15, randomforestclassifier__n_estimators=220, randomforestclassifier__warm_start=True;, score=nan total time=   0.0s\n",
            "[CV 3/3] END randomforestclassifier__bootstrap=False, randomforestclassifier__class_weight=None, randomforestclassifier__criterion=log_loss, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=6, randomforestclassifier__min_samples_leaf=15, randomforestclassifier__n_estimators=220, randomforestclassifier__warm_start=True;, score=nan total time=   0.0s\n",
            "[CV 1/3] END randomforestclassifier__bootstrap=True, randomforestclassifier__class_weight=None, randomforestclassifier__criterion=log_loss, randomforestclassifier__max_depth=6, randomforestclassifier__max_features=10, randomforestclassifier__min_samples_leaf=25, randomforestclassifier__n_estimators=220, randomforestclassifier__warm_start=False;, score=nan total time=   0.0s\n",
            "[CV 2/3] END randomforestclassifier__bootstrap=True, randomforestclassifier__class_weight=None, randomforestclassifier__criterion=log_loss, randomforestclassifier__max_depth=6, randomforestclassifier__max_features=10, randomforestclassifier__min_samples_leaf=25, randomforestclassifier__n_estimators=220, randomforestclassifier__warm_start=False;, score=nan total time=   0.0s\n",
            "[CV 3/3] END randomforestclassifier__bootstrap=True, randomforestclassifier__class_weight=None, randomforestclassifier__criterion=log_loss, randomforestclassifier__max_depth=6, randomforestclassifier__max_features=10, randomforestclassifier__min_samples_leaf=25, randomforestclassifier__n_estimators=220, randomforestclassifier__warm_start=False;, score=nan total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:765: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3] END randomforestclassifier__bootstrap=False, randomforestclassifier__class_weight=balanced_subsample, randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=2, randomforestclassifier__min_samples_leaf=4, randomforestclassifier__n_estimators=210, randomforestclassifier__warm_start=True;, score=0.992 total time=   2.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:765: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/3] END randomforestclassifier__bootstrap=False, randomforestclassifier__class_weight=balanced_subsample, randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=2, randomforestclassifier__min_samples_leaf=4, randomforestclassifier__n_estimators=210, randomforestclassifier__warm_start=True;, score=0.996 total time=   2.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:765: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3] END randomforestclassifier__bootstrap=False, randomforestclassifier__class_weight=balanced_subsample, randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=2, randomforestclassifier__min_samples_leaf=4, randomforestclassifier__n_estimators=210, randomforestclassifier__warm_start=True;, score=0.996 total time=   3.8s\n",
            "[CV 1/3] END randomforestclassifier__bootstrap=False, randomforestclassifier__class_weight=balanced, randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=25, randomforestclassifier__min_samples_leaf=30, randomforestclassifier__n_estimators=220, randomforestclassifier__warm_start=True;, score=nan total time=   0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:765: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
            "  warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:765: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/3] END randomforestclassifier__bootstrap=False, randomforestclassifier__class_weight=balanced, randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=25, randomforestclassifier__min_samples_leaf=30, randomforestclassifier__n_estimators=220, randomforestclassifier__warm_start=True;, score=nan total time=   1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:765: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3] END randomforestclassifier__bootstrap=False, randomforestclassifier__class_weight=balanced, randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=25, randomforestclassifier__min_samples_leaf=30, randomforestclassifier__n_estimators=220, randomforestclassifier__warm_start=True;, score=nan total time=   1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:765: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3] END randomforestclassifier__bootstrap=False, randomforestclassifier__class_weight=balanced_subsample, randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=6, randomforestclassifier__min_samples_leaf=15, randomforestclassifier__n_estimators=190, randomforestclassifier__warm_start=False;, score=0.991 total time=   3.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:765: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/3] END randomforestclassifier__bootstrap=False, randomforestclassifier__class_weight=balanced_subsample, randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=6, randomforestclassifier__min_samples_leaf=15, randomforestclassifier__n_estimators=190, randomforestclassifier__warm_start=False;, score=0.995 total time=   2.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:765: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3] END randomforestclassifier__bootstrap=False, randomforestclassifier__class_weight=balanced_subsample, randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=6, randomforestclassifier__min_samples_leaf=15, randomforestclassifier__n_estimators=190, randomforestclassifier__warm_start=False;, score=0.996 total time=   2.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:765: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3] END randomforestclassifier__bootstrap=False, randomforestclassifier__class_weight=balanced, randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=25, randomforestclassifier__max_features=6, randomforestclassifier__min_samples_leaf=20, randomforestclassifier__n_estimators=200, randomforestclassifier__warm_start=False;, score=0.989 total time=   3.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:765: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/3] END randomforestclassifier__bootstrap=False, randomforestclassifier__class_weight=balanced, randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=25, randomforestclassifier__max_features=6, randomforestclassifier__min_samples_leaf=20, randomforestclassifier__n_estimators=200, randomforestclassifier__warm_start=False;, score=0.995 total time=   3.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:765: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3] END randomforestclassifier__bootstrap=False, randomforestclassifier__class_weight=balanced, randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=25, randomforestclassifier__max_features=6, randomforestclassifier__min_samples_leaf=20, randomforestclassifier__n_estimators=200, randomforestclassifier__warm_start=False;, score=0.994 total time=   2.2s\n",
            "[CV 1/3] END randomforestclassifier__bootstrap=False, randomforestclassifier__class_weight=balanced, randomforestclassifier__criterion=log_loss, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=15, randomforestclassifier__min_samples_leaf=2, randomforestclassifier__n_estimators=200, randomforestclassifier__warm_start=True;, score=nan total time=   0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:765: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
            "  warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:765: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/3] END randomforestclassifier__bootstrap=False, randomforestclassifier__class_weight=balanced, randomforestclassifier__criterion=log_loss, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=15, randomforestclassifier__min_samples_leaf=2, randomforestclassifier__n_estimators=200, randomforestclassifier__warm_start=True;, score=nan total time=   1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:765: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3] END randomforestclassifier__bootstrap=False, randomforestclassifier__class_weight=balanced, randomforestclassifier__criterion=log_loss, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=15, randomforestclassifier__min_samples_leaf=2, randomforestclassifier__n_estimators=200, randomforestclassifier__warm_start=True;, score=nan total time=   1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:765: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3] END randomforestclassifier__bootstrap=False, randomforestclassifier__class_weight=balanced, randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=25, randomforestclassifier__min_samples_leaf=30, randomforestclassifier__n_estimators=220, randomforestclassifier__warm_start=True;, score=nan total time=   1.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:765: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/3] END randomforestclassifier__bootstrap=False, randomforestclassifier__class_weight=balanced, randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=25, randomforestclassifier__min_samples_leaf=30, randomforestclassifier__n_estimators=220, randomforestclassifier__warm_start=True;, score=nan total time=   1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:765: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3] END randomforestclassifier__bootstrap=False, randomforestclassifier__class_weight=balanced, randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=25, randomforestclassifier__min_samples_leaf=30, randomforestclassifier__n_estimators=220, randomforestclassifier__warm_start=True;, score=nan total time=   1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:765: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3] END randomforestclassifier__bootstrap=False, randomforestclassifier__class_weight=balanced_subsample, randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=10, randomforestclassifier__min_samples_leaf=30, randomforestclassifier__n_estimators=210, randomforestclassifier__warm_start=True;, score=0.981 total time=   8.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:765: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/3] END randomforestclassifier__bootstrap=False, randomforestclassifier__class_weight=balanced_subsample, randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=10, randomforestclassifier__min_samples_leaf=30, randomforestclassifier__n_estimators=210, randomforestclassifier__warm_start=True;, score=0.990 total time=   3.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:765: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3] END randomforestclassifier__bootstrap=False, randomforestclassifier__class_weight=balanced_subsample, randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=10, randomforestclassifier__min_samples_leaf=30, randomforestclassifier__n_estimators=210, randomforestclassifier__warm_start=True;, score=0.989 total time=   3.3s\n",
            "[CV 1/3] END randomforestclassifier__bootstrap=True, randomforestclassifier__class_weight=None, randomforestclassifier__criterion=log_loss, randomforestclassifier__max_depth=20, randomforestclassifier__max_features=6, randomforestclassifier__min_samples_leaf=25, randomforestclassifier__n_estimators=200, randomforestclassifier__warm_start=True;, score=nan total time=   0.0s\n",
            "[CV 2/3] END randomforestclassifier__bootstrap=True, randomforestclassifier__class_weight=None, randomforestclassifier__criterion=log_loss, randomforestclassifier__max_depth=20, randomforestclassifier__max_features=6, randomforestclassifier__min_samples_leaf=25, randomforestclassifier__n_estimators=200, randomforestclassifier__warm_start=True;, score=nan total time=   0.0s\n",
            "[CV 3/3] END randomforestclassifier__bootstrap=True, randomforestclassifier__class_weight=None, randomforestclassifier__criterion=log_loss, randomforestclassifier__max_depth=20, randomforestclassifier__max_features=6, randomforestclassifier__min_samples_leaf=25, randomforestclassifier__n_estimators=200, randomforestclassifier__warm_start=True;, score=nan total time=   0.0s\n",
            "[CV 1/3] END randomforestclassifier__bootstrap=False, randomforestclassifier__class_weight=balanced_subsample, randomforestclassifier__criterion=log_loss, randomforestclassifier__max_depth=25, randomforestclassifier__max_features=10, randomforestclassifier__min_samples_leaf=8, randomforestclassifier__n_estimators=210, randomforestclassifier__warm_start=True;, score=nan total time=   0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:765: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
            "  warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:765: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/3] END randomforestclassifier__bootstrap=False, randomforestclassifier__class_weight=balanced_subsample, randomforestclassifier__criterion=log_loss, randomforestclassifier__max_depth=25, randomforestclassifier__max_features=10, randomforestclassifier__min_samples_leaf=8, randomforestclassifier__n_estimators=210, randomforestclassifier__warm_start=True;, score=nan total time=   1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:765: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3] END randomforestclassifier__bootstrap=False, randomforestclassifier__class_weight=balanced_subsample, randomforestclassifier__criterion=log_loss, randomforestclassifier__max_depth=25, randomforestclassifier__max_features=10, randomforestclassifier__min_samples_leaf=8, randomforestclassifier__n_estimators=210, randomforestclassifier__warm_start=True;, score=nan total time=   1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "60 fits failed out of a total of 90.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "24 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\", line 394, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py\", line 367, in fit\n",
            "    y, expanded_class_weight = self._validate_y_class_weight(y)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py\", line 758, in _validate_y_class_weight\n",
            "    raise ValueError(\n",
            "ValueError: Valid presets for class_weight include \"balanced\" and \"balanced_subsample\".Given \"None\".\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "29 fits failed with the following error:\n",
            "joblib.externals.loky.process_executor._RemoteTraceback: \n",
            "\"\"\"\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/externals/loky/process_executor.py\", line 428, in _process_worker\n",
            "    r = call_item()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/externals/loky/process_executor.py\", line 275, in __call__\n",
            "    return self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\", line 620, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py\", line 185, in _parallel_build_trees\n",
            "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/tree/_classes.py\", line 937, in fit\n",
            "    super().fit(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/tree/_classes.py\", line 308, in fit\n",
            "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
            "ValueError: max_features must be in (0, n_features]\n",
            "\"\"\"\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\", line 394, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py\", line 450, in fit\n",
            "    trees = Parallel(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 1098, in __call__\n",
            "    self.retrieve()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 975, in retrieve\n",
            "    self._output.extend(job.get(timeout=self.timeout))\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\", line 567, in wrap_future_result\n",
            "    return future.result(timeout=timeout)\n",
            "  File \"/usr/lib/python3.8/concurrent/futures/_base.py\", line 444, in result\n",
            "    return self.__get_result()\n",
            "  File \"/usr/lib/python3.8/concurrent/futures/_base.py\", line 389, in __get_result\n",
            "    raise self._exception\n",
            "ValueError: max_features must be in (0, n_features]\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "6 fits failed with the following error:\n",
            "joblib.externals.loky.process_executor._RemoteTraceback: \n",
            "\"\"\"\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/externals/loky/process_executor.py\", line 428, in _process_worker\n",
            "    r = call_item()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/externals/loky/process_executor.py\", line 275, in __call__\n",
            "    return self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\", line 620, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py\", line 185, in _parallel_build_trees\n",
            "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/tree/_classes.py\", line 937, in fit\n",
            "    super().fit(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/tree/_classes.py\", line 352, in fit\n",
            "    criterion = CRITERIA_CLF[self.criterion](\n",
            "KeyError: 'log_loss'\n",
            "\"\"\"\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\", line 394, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py\", line 450, in fit\n",
            "    trees = Parallel(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 1098, in __call__\n",
            "    self.retrieve()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 975, in retrieve\n",
            "    self._output.extend(job.get(timeout=self.timeout))\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\", line 567, in wrap_future_result\n",
            "    return future.result(timeout=timeout)\n",
            "  File \"/usr/lib/python3.8/concurrent/futures/_base.py\", line 444, in result\n",
            "    return self.__get_result()\n",
            "  File \"/usr/lib/python3.8/concurrent/futures/_base.py\", line 389, in __get_result\n",
            "    raise self._exception\n",
            "KeyError: 'log_loss'\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "joblib.externals.loky.process_executor._RemoteTraceback: \n",
            "\"\"\"\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/externals/loky/process_executor.py\", line 428, in _process_worker\n",
            "    r = call_item()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/externals/loky/process_executor.py\", line 275, in __call__\n",
            "    return self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\", line 620, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py\", line 185, in _parallel_build_trees\n",
            "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/tree/_classes.py\", line 937, in fit\n",
            "    super().fit(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/tree/_classes.py\", line 308, in fit\n",
            "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
            "ValueError: max_features must be in (0, n_features]\n",
            "\"\"\"\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\", line 394, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py\", line 450, in fit\n",
            "    trees = Parallel(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 1098, in __call__\n",
            "    self.retrieve()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 975, in retrieve\n",
            "    self._output.extend(job.get(timeout=self.timeout))\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\", line 567, in wrap_future_result\n",
            "    return future.result(timeout=timeout)\n",
            "  File \"/usr/lib/python3.8/concurrent/futures/_base.py\", line 437, in result\n",
            "    return self.__get_result()\n",
            "  File \"/usr/lib/python3.8/concurrent/futures/_base.py\", line 389, in __get_result\n",
            "    raise self._exception\n",
            "ValueError: max_features must be in (0, n_features]\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.98349444 0.98933237 0.9625707         nan        nan        nan\n",
            "        nan        nan        nan        nan        nan 0.98244643\n",
            " 0.99561461        nan 0.9972606         nan        nan        nan\n",
            "        nan        nan        nan 0.99460661        nan 0.99402642\n",
            " 0.99258147        nan        nan 0.98688815        nan        nan]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:765: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3,\n",
              "                   estimator=Pipeline(steps=[('randomforestclassifier',\n",
              "                                              RandomForestClassifier(n_jobs=-1,\n",
              "                                                                     oob_score=True,\n",
              "                                                                     random_state=2))]),\n",
              "                   n_iter=30,\n",
              "                   param_distributions={'randomforestclassifier__bootstrap': ['True',\n",
              "                                                                              'False'],\n",
              "                                        'randomforestclassifier__class_weight': ['None',\n",
              "                                                                                 'balanced',\n",
              "                                                                                 'balanced_subsample'],\n",
              "                                        'randomforestclassifier__criterion': ['gini'...\n",
              "                                        'randomforestclassifier__max_depth': [2,\n",
              "                                                                              4,\n",
              "                                                                              6,\n",
              "                                                                              8,\n",
              "                                                                              10,\n",
              "                                                                              15,\n",
              "                                                                              20,\n",
              "                                                                              25,\n",
              "                                                                              30],\n",
              "                                        'randomforestclassifier__max_features': [2,\n",
              "                                                                                 4,\n",
              "                                                                                 6,\n",
              "                                                                                 8,\n",
              "                                                                                 10,\n",
              "                                                                                 15,\n",
              "                                                                                 20,\n",
              "                                                                                 25,\n",
              "                                                                                 30],\n",
              "                                        'randomforestclassifier__min_samples_leaf': [2,\n",
              "                                                                                     4,\n",
              "                                                                                     6,\n",
              "                                                                                     8,\n",
              "                                                                                     10,\n",
              "                                                                                     15,\n",
              "                                                                                     20,\n",
              "                                                                                     25,\n",
              "                                                                                     30],\n",
              "                                        'randomforestclassifier__n_estimators': [180,\n",
              "                                                                                 190,\n",
              "                                                                                 200,\n",
              "                                                                                 210,\n",
              "                                                                                 220],\n",
              "                                        'randomforestclassifier__warm_start': ['True',\n",
              "                                                                               'False']},\n",
              "                   random_state=2, scoring='roc_auc', verbose=3)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"최적 하이퍼파라미터: \", randomized_search.best_params_)\n",
        "print(\"최적 roc_auc: \", randomized_search.best_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvDSfr8B7NFq",
        "outputId": "e0246543-e26c-49f6-de2b-a05ec217dbe7"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "최적 하이퍼파라미터:  {'randomforestclassifier__warm_start': 'True', 'randomforestclassifier__n_estimators': 200, 'randomforestclassifier__min_samples_leaf': 4, 'randomforestclassifier__max_features': 4, 'randomforestclassifier__max_depth': 20, 'randomforestclassifier__criterion': 'entropy', 'randomforestclassifier__class_weight': 'balanced_subsample', 'randomforestclassifier__bootstrap': 'False'}\n",
            "최적 roc_auc:  0.9972606021361176\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RFC = RandomForestClassifier(random_state=2, oob_score=True, n_jobs=-1, warm_start= True, n_estimators= 200, min_samples_leaf= 4, max_features= 4, max_depth= 20, criterion= 'entropy', class_weight= 'balanced_subsample')"
      ],
      "metadata": {
        "id": "7p90idHm9dHI"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RFC.fit(X_train_sampled, y_train_sampled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOK8l6SE9_wi",
        "outputId": "32124e32-46c5-4c65-dbbe-7d633f8a3203"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:765: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(class_weight='balanced_subsample', criterion='entropy',\n",
              "                       max_depth=20, max_features=4, min_samples_leaf=4,\n",
              "                       n_estimators=200, n_jobs=-1, oob_score=True,\n",
              "                       random_state=2, warm_start=True)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = y_val"
      ],
      "metadata": {
        "id": "aqOucEvz5c85"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_proba = RFC.predict_proba(X_test)[:,1]\n",
        "roc_auc_score(y_test, y_pred_proba)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpNDLCX-6Rw_",
        "outputId": "070f601d-d5de-49f7-eb7d-57c39eff43d2"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8954361054766734"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "permuter = PermutationImportance(\n",
        "    RFC,  # model\n",
        "    scoring=\"roc_auc\",  # metric\n",
        "    n_iter=10,  # 다른 random seed를 사용하여 10번 반복\n",
        "    random_state=2,\n",
        ")\n",
        "\n",
        "permuter.fit(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65525136-f1d6-4af7-de46-708706fcd69a",
        "id": "v5teUWMl-TXI"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PermutationImportance(estimator=RandomForestClassifier(class_weight='balanced_subsample',\n",
              "                                                       criterion='entropy',\n",
              "                                                       max_depth=20,\n",
              "                                                       max_features=4,\n",
              "                                                       min_samples_leaf=4,\n",
              "                                                       n_estimators=200,\n",
              "                                                       n_jobs=-1,\n",
              "                                                       oob_score=True,\n",
              "                                                       random_state=2,\n",
              "                                                       warm_start=True),\n",
              "                      n_iter=10, random_state=2, scoring='roc_auc')"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_names = X_test.columns.tolist()\n",
        "pi = pd.Series(permuter.feature_importances_, feature_names).sort_values()\n",
        "pi.plot.barh()\n",
        "plt.title(\"Permutation Importance\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "f6887699-df5d-47d7-a75e-398ccb413c61",
        "id": "ZYAczhud-TXI"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Permutation Importance')"
            ]
          },
          "metadata": {},
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eli5.show_weights(\n",
        "    permuter,\n",
        "    top=None,\n",
        "    feature_names=feature_names,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "id": "OqcdJveTA1Xm",
        "outputId": "3b7a4be4-b38a-47da-dbe6-57404c096546"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
              "    <thead>\n",
              "    <tr style=\"border: none;\">\n",
              "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
              "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "    </tr>\n",
              "    </thead>\n",
              "    <tbody>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.2209\n",
              "                \n",
              "                    &plusmn; 0.0499\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                category_parent\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 88.09%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.1054\n",
              "                \n",
              "                    &plusmn; 0.0428\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                category_name\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 97.73%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0098\n",
              "                \n",
              "                    &plusmn; 0.0284\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                backers_count\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.50%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0011\n",
              "                \n",
              "                    &plusmn; 0.0018\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                staff_pick\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 98.86%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0037\n",
              "                \n",
              "                    &plusmn; 0.0137\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                currency\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 98.81%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0039\n",
              "                \n",
              "                    &plusmn; 0.0156\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                goal\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 98.44%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0058\n",
              "                \n",
              "                    &plusmn; 0.0194\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                country\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 97.90%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0089\n",
              "                \n",
              "                    &plusmn; 0.0170\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                usd_pledged\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 97.24%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0130\n",
              "                \n",
              "                    &plusmn; 0.0238\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                pledged\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 96.40%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0191\n",
              "                \n",
              "                    &plusmn; 0.0296\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                converted_pledged_amount\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "    \n",
              "    </tbody>\n",
              "</table>\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    }
  ]
}